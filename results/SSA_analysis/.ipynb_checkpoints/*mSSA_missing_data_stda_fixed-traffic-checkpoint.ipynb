{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mssa.mssa import mSSA\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import io\n",
    "import numpy as np \n",
    "import torch \n",
    "import copy \n",
    "from sklearn.metrics import r2_score\n",
    "import os \n",
    "from datetime import datetime, timedelta\n",
    "from datetime import timedelta\n",
    "dev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"traffic.txt\"\n",
    "isExist = os.path.exists(file)\n",
    "if not isExist:\n",
    "    print(f\"Files not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded..\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Preprocess data\"\"\"\n",
    "data = pd.read_csv('traffic.txt', delimiter = ',', header=None)\n",
    "print('data loaded..')\n",
    "data_2 = data.copy()\n",
    "#pick the first 20 clients\n",
    "data_2 = data_2.iloc[:,:20]\n",
    "#create time column: 2 years 1 hour\n",
    "data_2['time'] = pd.to_datetime(np.arange(datetime(2015,1,1), datetime(2017,1,1), timedelta(hours=1)))\n",
    "data_2.index = data_2['time']\n",
    "data_2 = data_2.drop(['time'], axis = 1)\n",
    "#create column names\n",
    "data_3 = data_2.copy()\n",
    "col_names = ['MT_{0:03}'.format(i+1) for i in range(data_3.shape[1])]\n",
    "data_3.columns = col_names\n",
    "aggregated_data = data_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17544, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "Std_normalization = 1\n",
    "if Std_normalization:\n",
    "    scaler = StandardScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "    norm_means = scaler.mean_\n",
    "    norm_std = scaler.scale_\n",
    "else:\n",
    "    scaler = MinMaxScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "global data_4\n",
    "normalized_data = pd.DataFrame(temp, index=aggregated_data.index, columns = aggregated_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>-0.936348</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>-0.569033</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>-0.660995</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>-0.914064</td>\n",
       "      <td>-0.568700</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>-0.488945</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>-0.407787</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.514071</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>-0.901844</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>-0.826841</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>-0.672342</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>-0.810024</td>\n",
       "      <td>-0.959996</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>-0.923742</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>-1.321309</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>-1.233545</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143 -0.936348 -1.154807 -0.569033   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168 -0.826841 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566 -0.660995 -0.414196   \n",
       "2015-01-01 01:00:00 -0.488945 -0.701394 -0.490022 -0.447094 -0.407787   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00 -0.672342 -0.886640 -0.810024 -0.959996 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473 -0.914064 -0.568700 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055 -0.901844 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059 -0.923742 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622 -1.233545   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432 -0.748872 -0.514071 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993 -1.321309 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    cols = normalized_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    test_df = normalized_data.iloc[:5][cols[:5]].copy()\n",
    "    np_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    \"\"\"Inject missing data\"\"\"\n",
    "    # Convert original data to 1d array - Because existing package only supports randomly choose from 1d array\n",
    "    np_test_1d = np_test.flatten()\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    total_elem = np_test_1d.shape[0]\n",
    "    missing_percentage = 50\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100) \n",
    "    print(number_of_missing_elem)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False)\n",
    "    np_test_1d[missing_index] = 0\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    np_test_2d = np_test_1d.reshape(5,-1)\n",
    "    np_test_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143  0.000000 -1.154807  0.000000   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168  0.000000 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566  0.000000 -0.414196   \n",
       "2015-01-01 01:00:00  0.000000 -0.701394 -0.490022 -0.447094  0.000000   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00  0.000000 -0.886640  0.000000  0.000000 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473  0.000000  0.000000 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055  0.000000 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059  0.000000 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622  0.000000   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432  0.000000  0.000000 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993  0.000000 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Create missing values based on normal distribution random choice\n",
    "\n",
    "Input: \n",
    " - pd_data: 2d pandas data frame\n",
    " - missing_percentage: missing percentage <= 100\n",
    "\n",
    "Output:\n",
    " - return_data: 2d pandas with missed values\n",
    "\n",
    "\"\"\"\n",
    "def create_missing_data(pd_data, missing_percentage = 20):\n",
    "    assert missing_percentage <= 100, \"missing percentage should be less than or equal 100%\"\n",
    "    np.random.seed(1993)\n",
    "    # Convert data frame to array\n",
    "    np_data = pd_data.to_numpy()\n",
    "    # Convert original data to 1d array - Because existing package only supports to randomly choose indices from 1d array\n",
    "    np_data_1d = np_data.flatten()\n",
    "    # Randomly choose missing index\n",
    "    total_elem = np_data_1d.shape[0]\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False) # with replace = False, an index only is chosen 1 time\n",
    "    # Replace missing_index with 0\n",
    "    np_data_1d[missing_index] = 0\n",
    "    # Convert 1d array to 2d array\n",
    "    np_data_2d = np_data_1d.reshape(pd_data.shape[0], pd_data.shape[1])\n",
    "    # Convert 2d array to dataframe\n",
    "    cols_name = pd_data.columns\n",
    "    return_data = pd.DataFrame(np_data_2d, columns = cols_name)\n",
    "    return_data.index = pd_data.index\n",
    "    return return_data\n",
    "\n",
    "missing_df = create_missing_data(normalized_data, missing_percentage=20)\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_clients; global data_train; global data_test\n",
    "def set_train_test(n_clients=20):\n",
    "    data_train = normalized_data.iloc[:17376,:n_clients] \n",
    "    data_test = normalized_data.iloc[17376:,:n_clients]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17376, 20)\n",
      "(168, 20)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = set_train_test(n_clients=370)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_obs(data_train, L=80):\n",
    "    df = data_train\n",
    "    N = df.shape[1]\n",
    "#     col_to_row_ratio = 4\n",
    "\n",
    "    T = df.shape[0]\n",
    "\n",
    "    M = int(df.size / L)\n",
    "    if M%N != 0:\n",
    "        M -= M%N\n",
    "    M_ts = M // N\n",
    "    # inc_obs = np.array(df.iloc[:M_ts*L,:]) # first range, we use second range for traning\n",
    "    inc_obs = np.array(df.iloc[T%L:,:]) # second range, note its not T%L+1 due to python index\n",
    "    normalize = False\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        inc_obs = scaler.fit_transform(inc_obs)\n",
    "        norm_means = scaler.mean_\n",
    "        norm_std = scaler.scale_\n",
    "\n",
    "    flattened_obs = inc_obs.reshape([L,M], order = 'F') # 按照列顺序\n",
    "    # flattened_obs = flattened_obs[:,np.arange(M_ts*self.no_ts).reshape([self.no_ts,M_ts]).flatten('F')] # 这里导致第二列是ts2，stacked page是不同ts交错组成\n",
    "    return flattened_obs, M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global N; global M_ts; global L; global window\n",
    "L = 80\n",
    "flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "window = M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_day(data_test, model, weights, days=7):\n",
    "    # predict for seven days\n",
    "    # days = 7\n",
    "\n",
    "    #initialise prediction array\n",
    "    predictions = np.zeros((len(data_test.columns),24*days))\n",
    "    ub = np.zeros((len(data_test.columns),24*days))\n",
    "    lb = np.zeros((len(data_test.columns),24*days))\n",
    "\n",
    "    # specify start time\n",
    "    start_time = pd.Timestamp('2016-12-25 00:00:00')\n",
    "\n",
    "    # actual = data_test.values[:24*days,:]\n",
    "\n",
    "    # obtain new actual by index, new test start from 2014-12-02-17:00\n",
    "    actual = data_test[data_test.index>=start_time].values[:24*days,:]\n",
    "\n",
    "\n",
    "    for day in range(days):\n",
    "        # get the final time stamp in the day\n",
    "        end_time = start_time + pd.Timedelta(hours=23)\n",
    "        # convert timestamps to string\n",
    "        start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # predict for each house\n",
    "        for i, column in enumerate(data_test.columns):\n",
    "            # Forecast\n",
    "            df_30 = model.predict(column,start_str,end_str)\n",
    "            predictions[i,day*24:(day+1)*24] = df_30['Mean Predictions']\n",
    "            ub[i,day*24:(day+1)*24] = df_30['Upper Bound']\n",
    "            lb[i,day*24:(day+1)*24] = df_30['Lower Bound']\n",
    "\n",
    "        # fit the model with the already predicted values \n",
    "\n",
    "        # df_insert = data_test.iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # obtain new df_insert\n",
    "        # df_insert = data_test[data_test.index>=start_time].iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # model.update_model(df_insert)\n",
    "    \n",
    "        if weights is not None:\n",
    "            model.ts_model.models[0].weights = weights\n",
    "\n",
    "        # update start_time\n",
    "        start_time = start_time + pd.Timedelta(hours=24)\n",
    "    return actual, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sd(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users] # Debug1\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "    # stand-alone ssa\n",
    "    window = M_ts\n",
    "    lst_U_sd = []\n",
    "    for i in range(n_users):\n",
    "        data = flattened_obs[:,i*window:(i+1)*window]\n",
    "        U,_,_ = np.linalg.svd(data)\n",
    "        U = U[:,:dim]\n",
    "        lst_U_sd.append(U)\n",
    "\n",
    "    P_sd = flattened_obs\n",
    "    P_sd_hat = []\n",
    "    y_sd = []\n",
    "    y_true = P_sd[-1,:]\n",
    "    P_tilde_sd_hat = []\n",
    "    imputation_model_score_sd = []\n",
    "    actual = []; predictions_sd = []\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        P_i_sd = P_sd[:,int(i*window):int((i+1)*window)]\n",
    "        P_i_sd_hat = lst_U_sd[i].dot(lst_U_sd[i].T.dot(P_i_sd)); P_sd_hat.append(P_i_sd_hat)\n",
    "        y_i_sd = P_i_sd_hat[-1,:]; y_sd.append(y_i_sd)\n",
    "        y_i_true = P_i_sd[-1,:]\n",
    "        P_i_tilde_sd_hat = P_i_sd_hat[:-1,:]; P_tilde_sd_hat.append(P_i_tilde_sd_hat)\n",
    "        imputation_model_score_sd.append(r2_score(P_i_sd.flatten('F'),P_i_sd_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "        # prediction\n",
    "        reg = LinearRegression(fit_intercept=False).fit(P_i_tilde_sd_hat.T, y_i_sd)\n",
    "        weights_sd_i = reg.coef_\n",
    "        model_sd = mSSA(rank = dim, normalize = False, L=L)\n",
    "        model_sd.update_model(pd.DataFrame(data_train.iloc[:,i]))\n",
    "        model_sd.ts_model.models[0].weights = weights_sd_i\n",
    "        actual_i, predictions_sd_i = predict_one_day(pd.DataFrame(data_test.iloc[:,i]), model_sd, weights_sd_i)\n",
    "        actual.append(actual_i); predictions_sd.append(predictions_sd_i.T)\n",
    "    imputation_model_score_sd = np.array(imputation_model_score_sd)\n",
    "    P_sd_hat = np.hstack(P_sd_hat)\n",
    "    y_sd = np.hstack(y_sd)\n",
    "    P_tilde_sd_hat = np.hstack(P_tilde_sd_hat)\n",
    "    actual = np.hstack(actual); predictions_sd = np.hstack(predictions_sd)\n",
    "    print(\"imputation score:\", imputation_model_score_sd.mean())\n",
    "    \n",
    "    Y = actual[:,:]\n",
    "    Y_h_sd = predictions_sd[:,:]\n",
    "    mse_sd = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_sd[:24*days]))) # Debug2\n",
    "    print('Forecasting accuracy (RMSE) my:',mse_sd)\n",
    "    rmse_sd = mse_sd\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "    #         plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "            plt.plot(predictions_sd.T[i,:24*days],label= 'sd',color='pink')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_sd, _, lst_U_sd, rmse_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mssa(data_train, data_test, rank, L, n_users, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    model = mSSA(rank = rank, normalize = False, L=L)\n",
    "    \n",
    "    # model\n",
    "    model.update_model(data_train)\n",
    "    actual, predictions = predict_one_day(data_test, model, None)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h = predictions.T[:,:]\n",
    "    mse = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h[:24*days])))\n",
    "    print ('Forecasting accuracy (RMSE):',mse)\n",
    "    rmse_mssa = mse \n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "            plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h, model.ts_model.models[0].weights, rmse_mssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fedMssa(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single, missingVal=1):\n",
    "    suffix_missingVal = 'missingVal' if missingVal else 'fullObs'\n",
    "    \n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "\n",
    "    # model\n",
    "    model_my = mSSA(rank = dim, normalize = False, L=L)\n",
    "    # model\n",
    "    model_my.update_model(data_train)\n",
    "\n",
    "    P_admm = flattened_obs\n",
    "    # ============================================================\n",
    "    # ====== 1. read common U from npy, which is Z\n",
    "#     results_path = f\"../SSA/\"\n",
    "#     file_name = f\"Grassmann_ADMM_constraint2_Traffic{n_users}_{suffix_missingVal}_N{n_users}_L{L}_d{L}_rhoauto_imputation.npy\"\n",
    "#     file_path = os.path.join(results_path, file_name)\n",
    "#     Uk_admm = np.load(file_path)\n",
    "#     # Select PCs by Sigma\n",
    "#     lst_U = []\n",
    "#     for i in range(n_users):\n",
    "#         proj_admm_i = Uk_admm.T.dot(P_admm[:,i*M_ts:(i+1)*M_ts])\n",
    "#         S2_admm_i_est = proj_admm_i.dot(proj_admm_i.T)\n",
    "#         S2_admm_i = np.diag(S2_admm_i_est)\n",
    "#         S_admm_i = np.sqrt(S2_admm_i)\n",
    "#         Uk_admm_i = Uk_admm[:,S_admm_i.argsort()[::-1][:dim]] # 针对每一个client，取Uk的那20列，which 取决于 S_admm的大小\n",
    "#         lst_U.append(Uk_admm_i)\n",
    "    # ============================================================\n",
    "        \n",
    "    # ============================================================\n",
    "    # ====== 2. read personalized U from h5, which is Ui\n",
    "    results_path = f\"../SSA/\"\n",
    "    file_name = f\"Grassmann_ADMM_constraint2_Traffic{n_users}_{suffix_missingVal}_N{n_users}_L{L}_d{L}_rhoauto_imputation.h5\"\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    lst_U = []\n",
    "    import h5py\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        # Print all root level object names (aka keys) \n",
    "        # these can be group or dataset names \n",
    "#         print(\"Keys: %s\" % f.keys())\n",
    "        # get first object name/key; may or may NOT be a group\n",
    "        for a_group_key in list(f.keys()):\n",
    "            ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "            lst_U.append(ds_arr)\n",
    "    # Select PCs by Sigma\n",
    "    for i in range(n_users):\n",
    "        proj_admm_i = lst_U[i].T.dot(P_admm[:,i*M_ts:(i+1)*M_ts])\n",
    "        S2_admm_i_est = proj_admm_i.dot(proj_admm_i.T)\n",
    "        S2_admm_i = np.diag(S2_admm_i_est)\n",
    "        S_admm_i = np.sqrt(S2_admm_i)\n",
    "        Uk_admm_i = lst_U[i][:,S_admm_i.argsort()[::-1][:dim]] # 针对每一个client，取Uk的那20列，which 取决于 S_admm的大小\n",
    "        lst_U[i] = Uk_admm_i\n",
    "    # ============================================================\n",
    "    \n",
    "    # Select PCs randomly\n",
    "#     select_idx = np.random.choice(np.arange(L),dim,replace=False)\n",
    "#     lst_U = []\n",
    "#     for i in range(n_users):\n",
    "#         lst_U.append(Uk_admm[:,:dim])\n",
    "#     print(\"Uk shape: \", lst_U[0].shape)\n",
    "\n",
    "    imputation_model_score_admm = []\n",
    "    \n",
    "    P_admm_hat = []\n",
    "    y_admm = []\n",
    "    y_true = P_admm[-1,:]\n",
    "    P_tilde_admm_hat = []\n",
    "    window = M_ts\n",
    "    for i in range(n_users):\n",
    "        P_i_admm = P_admm[:,int(i*window):int((i+1)*window)]\n",
    "        P_i_admm_hat = lst_U[i].dot(lst_U[i].T.dot(P_i_admm)); P_admm_hat.append(P_i_admm_hat)\n",
    "        y_i_admm = P_i_admm_hat[-1,:]; y_admm.append(y_i_admm)\n",
    "        y_i_true = P_i_admm[-1,:]\n",
    "        P_i_tilde_admm_hat = P_i_admm_hat[:-1,:]; P_tilde_admm_hat.append(P_i_tilde_admm_hat)\n",
    "        imputation_model_score_admm.append(r2_score(P_i_admm.flatten('F'),P_i_admm_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "    imputation_model_score_admm = np.array(imputation_model_score_admm)\n",
    "    P_admm_hat = np.hstack(P_admm_hat)\n",
    "    y_admm = np.hstack(y_admm)\n",
    "    P_tilde_admm_hat = np.hstack(P_tilde_admm_hat)\n",
    "\n",
    "    print(\"imputation score\", imputation_model_score_admm.mean())\n",
    "\n",
    "    # verify weights_admm using sklearn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg = LinearRegression(fit_intercept=False).fit(P_tilde_admm_hat.T, y_admm)\n",
    "    weights_LR = reg.coef_\n",
    "    \n",
    "    model_my.ts_model.models[0].weights = weights_LR\n",
    "    \n",
    "    actual, predictions_my = predict_one_day(data_test, model_my, weights_LR)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h_my = predictions_my.T[:,:]\n",
    "    mse_my = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_my[:24*days])))\n",
    "    print ('Forecasting accuracy (RMSE) my:',mse_my)\n",
    "    rmse_fedmssa = mse_my\n",
    "\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,25)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*7],label= 'mSSA',color='green')\n",
    "            plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "        #     plt.plot(predictions_sd[i,:24*7],label= 'sd',color='pink')\n",
    "        #     plt.fill_between(np.arange(24*7), lb[i,:24*7], ub[i,:24*7], alpha = 0.1)\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_my, weights_LR, lst_U, rmse_fedmssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17376, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals = create_missing_data(data_train, missing_percentage=20)\n",
    "data_train_missing_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>-0.826841</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143  0.000000 -1.154807  0.000000   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168 -0.826841 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566  0.000000 -0.414196   \n",
       "2015-01-01 01:00:00  0.000000 -0.701394 -0.490022 -0.447094  0.000000   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00  0.000000 -0.886640  0.000000  0.000000 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473  0.000000  0.000000 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055  0.000000 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059  0.000000 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622  0.000000   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432  0.000000  0.000000 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993  0.000000 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_csv_data:\n",
    "    for i in range(data_train_missing_vals.shape[1]):\n",
    "        data_train_missing_vals.iloc[:,i].to_csv('../../data/traffic_train_missing_20/'+ 'MT_{0:03}'.format(i+1) + '.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test for 20 users, each user contain a time series data:\n",
    "\n",
    "Setting:\n",
    "- 20 users\n",
    "- each global training round select 10% of users\n",
    "- 20% missing values\n",
    "- each user has a time series data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation score: 0.8330753633221162\n",
      "Forecasting accuracy (RMSE) my: 0.7263737410718833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7263737410718833]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sd = []\n",
    "for dim in range(1):\n",
    "    Y1, Y_sd, weights_sd, lst_U_sd, rmse = test_sd(data_train_missing_vals, data_test, L=100, n_users=20, M_ts=window, dim=25, days=2, plot_all=False, plot_single=False)\n",
    "    rmse_sd.append(rmse)\n",
    "rmse_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting accuracy (RMSE): 0.5545909443989689\n"
     ]
    }
   ],
   "source": [
    "rmse_mssa = []\n",
    "for rank in range(1):\n",
    "    Y2, Y_mssa, weights_mssa, rmse = test_mssa(data_train_missing_vals, data_test, rank=25, L=100, n_users=20, days=1, plot_all=False, plot_single=False)\n",
    "    rmse_mssa.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['MT_001', 'MT_002', 'MT_003', 'MT_004', 'MT_005', 'MT_006', 'MT_007', 'MT_008', 'MT_009', 'MT_010', 'MT_011', 'MT_012', 'MT_013', 'MT_014', 'MT_015', 'MT_016', 'MT_017', 'MT_018', 'MT_019', 'MT_020']>\n",
      "imputation score 0.498844029470758\n",
      "Forecasting accuracy (RMSE) my: 0.5458671678155741\n"
     ]
    }
   ],
   "source": [
    "rmse_fedmssa = []\n",
    "for dim in range(1):\n",
    "    Y3, Y_my, weights_my, lst_U_my, rmse = test_fedMssa(data_train_missing_vals, data_test, L=100, n_users=20, M_ts=window, dim=25, days=2, plot_all=False, plot_single=False)\n",
    "    rmse_fedmssa.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = os.getcwd()\n",
    "# results_folder_path = os.path.join(directory, \"rmse\")\n",
    "# sd_file_name = \"sd_rmse_80_missing_20\"\n",
    "# mssa_file_name = \"mssa_rmse_80_missing_20\"\n",
    "# fedmssa_file_name = \"fedmssa_rmse_80_missing_20\"\n",
    "# sd_path = os.path.join(results_folder_path, sd_file_name)\n",
    "# mssa_path = os.path.join(results_folder_path, mssa_file_name)\n",
    "# fedmssa_path = os.path.join(results_folder_path, fedmssa_file_name)\n",
    "# rmse_sd_np = np.array(rmse_sd)\n",
    "# rmse_mssa_np = np.array(rmse_mssa)\n",
    "# rmse_fedmssa_np = np.array(rmse_fedmssa)\n",
    "# np.save(sd_path, rmse_sd_np)\n",
    "# np.save(mssa_path, rmse_mssa_np)\n",
    "# np.save(fedmssa_path, rmse_fedmssa_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  sd\n",
    "# x = range(1, 30)\n",
    "# plt.plot(x, rmse_sd_np[:29])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  mssa\n",
    "# x = range(1, 30)\n",
    "# plt.plot(x, rmse_mssa_np[:29])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  fedmssa\n",
    "# x = range(1, 31)\n",
    "# plt.plot(x, rmse_fedmssa_np[50:80])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = range(1, 31)\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# rmse_sd_best = rmse_sd_np[:30]\n",
    "# rmse_mssa_best = rmse_mssa_np[:30]\n",
    "# rmse_fedmssa_best = rmse_fedmssa_np[50:80]\n",
    "# plt.plot(x, rmse_sd_best, label=\"standalone ssa\")\n",
    "# plt.plot(x, rmse_mssa_best, label=\"centralized mssa\")\n",
    "# plt.plot(x, rmse_fedmssa_best, label=\"fedmssa\")\n",
    "# plt.title(\"RMSE\")\n",
    "# plt.legend(prop={'size': 20})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test for 370 users, each user contain a time series data:\n",
    "\n",
    "Setting:\n",
    "- 370 users\n",
    "- each global training round select 10% of users\n",
    "- 20% missing values\n",
    "- each user has a time series data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_sd() missing 1 required positional argument: 'plot_single'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     Y1, Y_sd, weights_sd, lst_U_sd \u001b[38;5;241m=\u001b[39m \u001b[43mtest_sd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train_missing_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m370\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: test_sd() missing 1 required positional argument: 'plot_single'"
     ]
    }
   ],
   "source": [
    "for dim in [1]:\n",
    "    Y1, Y_sd, weights_sd, lst_U_sd = test_sd(data_train_missing_vals, data_test, L=80, n_users=370, M_ts=window, dim=10, days=2, plot_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in [15]:\n",
    "    Y2, Y_mssa, weights_mssa = test_mssa(data_train_missing_vals, data_test, rank=10, L=80, n_users=370, days=2, plot_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y3, Y_my, weights_my, lst_U_my = test_fedMssa(data_train, data_test, L=80, n_users=370, M_ts=window, dim=74, days=2, plot_all=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1e19dcd35cebc7686e25e67905e0c169d820e97a342a12d63e068e8c4ead6c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
