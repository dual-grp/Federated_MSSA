{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mssa.mssa import mSSA\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import io\n",
    "import numpy as np \n",
    "import torch \n",
    "import copy \n",
    "from sklearn.metrics import r2_score\n",
    "import os \n",
    "dev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are ready\n"
     ]
    }
   ],
   "source": [
    "file = \"LD2011_2014_clean.txt\"\n",
    "isExist = os.path.exists(file)\n",
    "if not isExist:\n",
    "    !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip\n",
    "    !unzip LD2011_2014.txt.zip\n",
    "    # change commas to dots\n",
    "    !sed 's/,/./g' LD2011_2014.txt > LD2011_2014_clean.txt\n",
    "else: \n",
    "    print(f\"Files are ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded..\n",
      "Data aggregated by hour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26304, 370)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Preprocess data\"\"\"\n",
    "data = pd.read_csv('LD2011_2014_clean.txt', delimiter = ';')\n",
    "#remove data before 2012\n",
    "data = data.iloc[8760*4:]\n",
    "print('Data loaded..')\n",
    "data_2 = data.copy()\n",
    "#pick the first 20 houses\n",
    "data_2 = data_2.iloc[:,:]\n",
    "# Aggregate\n",
    "data_2['time'] =pd.to_datetime(data_2['Unnamed: 0']).dt.ceil('1h') \n",
    "data_2 = data_2.drop(['Unnamed: 0'], axis = 1)\n",
    "agg_dict = {}\n",
    "for col in data_2.columns[:-1]:\n",
    "    agg_dict[col] ='mean'\n",
    "aggregated_data = data_2.groupby(['time']).agg(agg_dict)\n",
    "print('Data aggregated by hour')\n",
    "aggregated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 370)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "Std_normalization = 1\n",
    "if Std_normalization:\n",
    "    scaler = StandardScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "    norm_means = scaler.mean_\n",
    "    norm_std = scaler.scale_\n",
    "else:\n",
    "    scaler = MinMaxScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "global data_4\n",
    "normalized_data = pd.DataFrame(temp, index=aggregated_data.index, columns = aggregated_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>-0.193637</td>\n",
       "      <td>-0.767048</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>1.297119</td>\n",
       "      <td>2.562526</td>\n",
       "      <td>0.380006</td>\n",
       "      <td>0.420689</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>1.237010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.925467</td>\n",
       "      <td>-0.660711</td>\n",
       "      <td>-0.611351</td>\n",
       "      <td>-0.924599</td>\n",
       "      <td>-1.182866</td>\n",
       "      <td>0.055241</td>\n",
       "      <td>-0.298429</td>\n",
       "      <td>-0.970811</td>\n",
       "      <td>-0.867907</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>-0.088516</td>\n",
       "      <td>-0.711666</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>1.174705</td>\n",
       "      <td>2.419487</td>\n",
       "      <td>0.131533</td>\n",
       "      <td>0.362440</td>\n",
       "      <td>0.666522</td>\n",
       "      <td>1.016322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.968145</td>\n",
       "      <td>-0.718147</td>\n",
       "      <td>-0.862776</td>\n",
       "      <td>-0.926923</td>\n",
       "      <td>-1.177477</td>\n",
       "      <td>-0.195217</td>\n",
       "      <td>-0.111780</td>\n",
       "      <td>-0.964607</td>\n",
       "      <td>-0.923605</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>-0.193637</td>\n",
       "      <td>-0.739357</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>0.710631</td>\n",
       "      <td>0.964851</td>\n",
       "      <td>1.573172</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.263732</td>\n",
       "      <td>0.500288</td>\n",
       "      <td>0.616982</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023433</td>\n",
       "      <td>-0.710625</td>\n",
       "      <td>-0.879452</td>\n",
       "      <td>-0.931572</td>\n",
       "      <td>-1.177477</td>\n",
       "      <td>-0.289139</td>\n",
       "      <td>-0.478750</td>\n",
       "      <td>-1.119708</td>\n",
       "      <td>-1.044284</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>-0.088516</td>\n",
       "      <td>-0.877811</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.179057</td>\n",
       "      <td>-0.948152</td>\n",
       "      <td>-0.559453</td>\n",
       "      <td>-0.391876</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.228097</td>\n",
       "      <td>-0.732505</td>\n",
       "      <td>-0.896128</td>\n",
       "      <td>-0.957141</td>\n",
       "      <td>-1.139759</td>\n",
       "      <td>-0.289139</td>\n",
       "      <td>-1.696712</td>\n",
       "      <td>-1.175544</td>\n",
       "      <td>-1.102634</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 05:00:00</th>\n",
       "      <td>-0.141076</td>\n",
       "      <td>-0.905502</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>-0.726679</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>-0.524736</td>\n",
       "      <td>-0.365412</td>\n",
       "      <td>-1.297643</td>\n",
       "      <td>-0.351661</td>\n",
       "      <td>-0.539002</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179598</td>\n",
       "      <td>-0.753702</td>\n",
       "      <td>-0.901901</td>\n",
       "      <td>-0.961790</td>\n",
       "      <td>-1.182866</td>\n",
       "      <td>-0.383061</td>\n",
       "      <td>-1.707784</td>\n",
       "      <td>-1.169340</td>\n",
       "      <td>-1.072133</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2012-01-01 01:00:00 -0.193637 -0.767048  5.979015  0.750556  1.297119   \n",
       "2012-01-01 02:00:00 -0.088516 -0.711666  5.979015  0.723940  1.174705   \n",
       "2012-01-01 03:00:00 -0.193637 -0.739357  5.979015  0.710631  0.964851   \n",
       "2012-01-01 04:00:00 -0.088516 -0.877811  5.979015 -0.194342  0.037999   \n",
       "2012-01-01 05:00:00 -0.141076 -0.905502  5.979015 -0.726679 -0.259294   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  ...  \\\n",
       "time                                                                   ...   \n",
       "2012-01-01 01:00:00  2.562526  0.380006  0.420689  0.936652  1.237010  ...   \n",
       "2012-01-01 02:00:00  2.419487  0.131533  0.362440  0.666522  1.016322  ...   \n",
       "2012-01-01 03:00:00  1.573172  0.090121 -0.263732  0.500288  0.616982  ...   \n",
       "2012-01-01 04:00:00  0.059340 -0.179057 -0.948152 -0.559453 -0.391876  ...   \n",
       "2012-01-01 05:00:00 -0.524736 -0.365412 -1.297643 -0.351661 -0.539002  ...   \n",
       "\n",
       "                       MT_361    MT_362    MT_363    MT_364    MT_365  \\\n",
       "time                                                                    \n",
       "2012-01-01 01:00:00 -0.925467 -0.660711 -0.611351 -0.924599 -1.182866   \n",
       "2012-01-01 02:00:00 -0.968145 -0.718147 -0.862776 -0.926923 -1.177477   \n",
       "2012-01-01 03:00:00 -1.023433 -0.710625 -0.879452 -0.931572 -1.177477   \n",
       "2012-01-01 04:00:00 -1.228097 -0.732505 -0.896128 -0.957141 -1.139759   \n",
       "2012-01-01 05:00:00 -1.179598 -0.753702 -0.901901 -0.961790 -1.182866   \n",
       "\n",
       "                       MT_366    MT_367    MT_368    MT_369    MT_370  \n",
       "time                                                                   \n",
       "2012-01-01 01:00:00  0.055241 -0.298429 -0.970811 -0.867907 -1.312616  \n",
       "2012-01-01 02:00:00 -0.195217 -0.111780 -0.964607 -0.923605 -1.312616  \n",
       "2012-01-01 03:00:00 -0.289139 -0.478750 -1.119708 -1.044284 -1.312616  \n",
       "2012-01-01 04:00:00 -0.289139 -1.696712 -1.175544 -1.102634 -1.312616  \n",
       "2012-01-01 05:00:00 -0.383061 -1.707784 -1.169340 -1.072133 -1.312616  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    cols = normalized_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    test_df = normalized_data.iloc[:5][cols[:5]].copy()\n",
    "    np_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    \"\"\"Inject missing data\"\"\"\n",
    "    # Convert original data to 1d array - Because existing package only supports randomly choose from 1d array\n",
    "    np_test_1d = np_test.flatten()\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    total_elem = np_test_1d.shape[0]\n",
    "    missing_percentage = 50\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100) \n",
    "    print(number_of_missing_elem)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False)\n",
    "    np_test_1d[missing_index] = 0\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    np_test_2d = np_test_1d.reshape(5,-1)\n",
    "    np_test_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>-0.193637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>1.297119</td>\n",
       "      <td>2.562526</td>\n",
       "      <td>0.380006</td>\n",
       "      <td>0.420689</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>1.237010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.660711</td>\n",
       "      <td>-0.611351</td>\n",
       "      <td>-0.924599</td>\n",
       "      <td>-1.182866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.298429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.867907</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>-0.088516</td>\n",
       "      <td>-0.711666</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131533</td>\n",
       "      <td>0.362440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.016322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.718147</td>\n",
       "      <td>-0.862776</td>\n",
       "      <td>-0.926923</td>\n",
       "      <td>-1.177477</td>\n",
       "      <td>-0.195217</td>\n",
       "      <td>-0.111780</td>\n",
       "      <td>-0.964607</td>\n",
       "      <td>-0.923605</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>-0.193637</td>\n",
       "      <td>-0.739357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>-0.263732</td>\n",
       "      <td>0.500288</td>\n",
       "      <td>0.616982</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023433</td>\n",
       "      <td>-0.710625</td>\n",
       "      <td>-0.879452</td>\n",
       "      <td>-0.931572</td>\n",
       "      <td>-1.177477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.119708</td>\n",
       "      <td>-1.044284</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.877811</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>-0.179057</td>\n",
       "      <td>-0.948152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.391876</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.228097</td>\n",
       "      <td>-0.732505</td>\n",
       "      <td>-0.896128</td>\n",
       "      <td>-0.957141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.289139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.175544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 05:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.905502</td>\n",
       "      <td>5.979015</td>\n",
       "      <td>-0.726679</td>\n",
       "      <td>-0.259294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.365412</td>\n",
       "      <td>-1.297643</td>\n",
       "      <td>-0.351661</td>\n",
       "      <td>-0.539002</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179598</td>\n",
       "      <td>-0.753702</td>\n",
       "      <td>-0.901901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.182866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.707784</td>\n",
       "      <td>-1.169340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2012-01-01 01:00:00 -0.193637  0.000000  0.000000  0.750556  1.297119   \n",
       "2012-01-01 02:00:00 -0.088516 -0.711666  5.979015  0.723940  0.000000   \n",
       "2012-01-01 03:00:00 -0.193637 -0.739357  0.000000  0.710631  0.000000   \n",
       "2012-01-01 04:00:00  0.000000 -0.877811  5.979015 -0.194342  0.037999   \n",
       "2012-01-01 05:00:00  0.000000 -0.905502  5.979015 -0.726679 -0.259294   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  ...  \\\n",
       "time                                                                   ...   \n",
       "2012-01-01 01:00:00  2.562526  0.380006  0.420689  0.936652  1.237010  ...   \n",
       "2012-01-01 02:00:00  0.000000  0.131533  0.362440  0.000000  1.016322  ...   \n",
       "2012-01-01 03:00:00  0.000000  0.090121 -0.263732  0.500288  0.616982  ...   \n",
       "2012-01-01 04:00:00  0.059340 -0.179057 -0.948152  0.000000 -0.391876  ...   \n",
       "2012-01-01 05:00:00  0.000000 -0.365412 -1.297643 -0.351661 -0.539002  ...   \n",
       "\n",
       "                       MT_361    MT_362    MT_363    MT_364    MT_365  \\\n",
       "time                                                                    \n",
       "2012-01-01 01:00:00  0.000000 -0.660711 -0.611351 -0.924599 -1.182866   \n",
       "2012-01-01 02:00:00  0.000000 -0.718147 -0.862776 -0.926923 -1.177477   \n",
       "2012-01-01 03:00:00 -1.023433 -0.710625 -0.879452 -0.931572 -1.177477   \n",
       "2012-01-01 04:00:00 -1.228097 -0.732505 -0.896128 -0.957141  0.000000   \n",
       "2012-01-01 05:00:00 -1.179598 -0.753702 -0.901901  0.000000 -1.182866   \n",
       "\n",
       "                       MT_366    MT_367    MT_368    MT_369    MT_370  \n",
       "time                                                                   \n",
       "2012-01-01 01:00:00  0.000000 -0.298429  0.000000 -0.867907 -1.312616  \n",
       "2012-01-01 02:00:00 -0.195217 -0.111780 -0.964607 -0.923605 -1.312616  \n",
       "2012-01-01 03:00:00  0.000000  0.000000 -1.119708 -1.044284  0.000000  \n",
       "2012-01-01 04:00:00 -0.289139  0.000000 -1.175544  0.000000 -1.312616  \n",
       "2012-01-01 05:00:00  0.000000 -1.707784 -1.169340  0.000000 -1.312616  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Create missing values based on normal distribution random choice\n",
    "\n",
    "Input: \n",
    " - pd_data: 2d pandas data frame\n",
    " - missing_percentage: missing percentage <= 100\n",
    "\n",
    "Output:\n",
    " - return_data: 2d pandas with missed values\n",
    "\n",
    "\"\"\"\n",
    "def create_missing_data(pd_data, missing_percentage = 20):\n",
    "    if missing_percentage == 0: return pd_data\n",
    "    assert missing_percentage <= 100, \"missing percentage should be less than or equal 100%\"\n",
    "    np.random.seed(1993)\n",
    "    # Convert data frame to array\n",
    "    np_data = pd_data.to_numpy()\n",
    "    # Convert original data to 1d array - Because existing package only supports to randomly choose indices from 1d array\n",
    "    np_data_1d = np_data.flatten()\n",
    "    # Randomly choose missing index\n",
    "    total_elem = np_data_1d.shape[0]\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False) # with replace = False, an index only is chosen 1 time\n",
    "    # Replace missing_index with 0\n",
    "    np_data_1d[missing_index] = 0\n",
    "    # Convert 1d array to 2d array\n",
    "    np_data_2d = np_data_1d.reshape(pd_data.shape[0], pd_data.shape[1])\n",
    "    # Convert 2d array to dataframe\n",
    "    cols_name = pd_data.columns\n",
    "    return_data = pd.DataFrame(np_data_2d, columns = cols_name)\n",
    "    return_data.index = pd_data.index\n",
    "    return return_data\n",
    "\n",
    "missing_df = create_missing_data(normalized_data, missing_percentage=20)\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_clients; global data_train; global data_test\n",
    "def set_train_test(n_clients=20):\n",
    "    data_train = normalized_data.iloc[:25968,:n_clients] #25600; 25968; 26082\n",
    "    data_test = normalized_data.iloc[25968:,:n_clients]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25968, 370), (336, 370))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = set_train_test(n_clients=370)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_obs(data_train, L=80):\n",
    "    df = data_train\n",
    "    N = df.shape[1]\n",
    "    col_to_row_ratio = 4\n",
    "\n",
    "    T = df.shape[0]\n",
    "\n",
    "    M = int(df.size / L)\n",
    "    if M%N != 0:\n",
    "        M -= M%N\n",
    "    M_ts = M // N\n",
    "    # inc_obs = np.array(df.iloc[:M_ts*L,:]) # first range, we use second range for traning\n",
    "    inc_obs = np.array(df.iloc[T%L:,:]) # second range, note its not T%L+1 due to python index\n",
    "    normalize = False\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        inc_obs = scaler.fit_transform(inc_obs)\n",
    "        norm_means = scaler.mean_\n",
    "        norm_std = scaler.scale_\n",
    "\n",
    "    flattened_obs = inc_obs.reshape([L,M], order = 'F') # 按照列顺序\n",
    "    # flattened_obs = flattened_obs[:,np.arange(M_ts*self.no_ts).reshape([self.no_ts,M_ts]).flatten('F')] # 这里导致第二列是ts2，stacked page是不同ts交错组成\n",
    "    return flattened_obs, M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global N; global M_ts; global L; global window\n",
    "L = 80\n",
    "flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "window = M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = 1\n",
    "predictions = np.zeros((len(data_test.columns),24*days))\n",
    "ub = np.zeros((len(data_test.columns),24*days))\n",
    "lb = np.zeros((len(data_test.columns),24*days))\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_day(data_test, model, weights, days=7):\n",
    "    # predict for seven days\n",
    "    # days = 7\n",
    "\n",
    "    #initialise prediction array\n",
    "    predictions = np.zeros((len(data_test.columns),24*days))\n",
    "    ub = np.zeros((len(data_test.columns),24*days))\n",
    "    lb = np.zeros((len(data_test.columns),24*days))\n",
    "\n",
    "    # specify start time\n",
    "    start_time = pd.Timestamp('2014-12-18 01:00:00')\n",
    "\n",
    "    # actual = data_test.values[:24*days,:]\n",
    "\n",
    "    # obtain new actual by index, new test start from 2014-12-02-17:00\n",
    "    actual = data_test[data_test.index>=start_time].values[:24*days,:]\n",
    "\n",
    "\n",
    "    for day in range(days):\n",
    "        # get the final time stamp in the day\n",
    "        end_time = start_time + pd.Timedelta(hours=23)\n",
    "        # convert timestamps to string\n",
    "        start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # predict for each house\n",
    "        for i, column in enumerate(data_test.columns):\n",
    "            # Forecast\n",
    "            df_30 = model.predict(column,start_str,end_str)\n",
    "            predictions[i,day*24:(day+1)*24] = df_30['Mean Predictions']\n",
    "            ub[i,day*24:(day+1)*24] = df_30['Upper Bound']\n",
    "            lb[i,day*24:(day+1)*24] = df_30['Lower Bound']\n",
    "\n",
    "        # fit the model with the already predicted values \n",
    "\n",
    "        # df_insert = data_test.iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # obtain new df_insert\n",
    "        # df_insert = data_test[data_test.index>=start_time].iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # model.update_model(df_insert)\n",
    "    \n",
    "        if weights is not None:\n",
    "            model.ts_model.models[0].weights = weights\n",
    "\n",
    "        # update start_time\n",
    "        start_time = start_time + pd.Timedelta(hours=24)\n",
    "    return actual, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sd(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users] # Debug1\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "    # stand-alone ssa\n",
    "    window = M_ts\n",
    "    lst_U_sd = []\n",
    "    for i in range(n_users):\n",
    "        data = flattened_obs[:,i*window:(i+1)*window]\n",
    "        U,_,_ = np.linalg.svd(data)\n",
    "        U = U[:,:dim]\n",
    "        lst_U_sd.append(U)\n",
    "\n",
    "    P_sd = flattened_obs\n",
    "    P_sd_hat = []\n",
    "    y_sd = []\n",
    "    y_true = P_sd[-1,:]\n",
    "    P_tilde_sd_hat = []\n",
    "    imputation_model_score_sd = []\n",
    "    actual = []; predictions_sd = []\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        P_i_sd = P_sd[:,int(i*window):int((i+1)*window)]\n",
    "        P_i_sd_hat = lst_U_sd[i].dot(lst_U_sd[i].T.dot(P_i_sd)); P_sd_hat.append(P_i_sd_hat)\n",
    "        y_i_sd = P_i_sd_hat[-1,:]; y_sd.append(y_i_sd)\n",
    "        y_i_true = P_i_sd[-1,:]\n",
    "        P_i_tilde_sd_hat = P_i_sd_hat[:-1,:]; P_tilde_sd_hat.append(P_i_tilde_sd_hat)\n",
    "        imputation_model_score_sd.append(r2_score(P_i_sd.flatten('F'),P_i_sd_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "        # prediction\n",
    "        reg = LinearRegression(fit_intercept=False).fit(P_i_tilde_sd_hat.T, y_i_sd)\n",
    "        weights_sd_i = reg.coef_\n",
    "        model_sd = mSSA(rank = dim, normalize = False, L=L)\n",
    "        model_sd.update_model(pd.DataFrame(data_train.iloc[:,i]))\n",
    "        model_sd.ts_model.models[0].weights = weights_sd_i\n",
    "        actual_i, predictions_sd_i = predict_one_day(pd.DataFrame(data_test.iloc[:,i]), model_sd, weights_sd_i)\n",
    "        actual.append(actual_i); predictions_sd.append(predictions_sd_i.T)\n",
    "    imputation_model_score_sd = np.array(imputation_model_score_sd)\n",
    "    P_sd_hat = np.hstack(P_sd_hat)\n",
    "    y_sd = np.hstack(y_sd)\n",
    "    P_tilde_sd_hat = np.hstack(P_tilde_sd_hat)\n",
    "    actual = np.hstack(actual); predictions_sd = np.hstack(predictions_sd)\n",
    "    print(\"imputation score:\", imputation_model_score_sd.mean())\n",
    "    \n",
    "    Y = actual[:,:]\n",
    "    Y_h_sd = predictions_sd[:,:]\n",
    "    mse_sd = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_sd[:24*days]))) # Debug2\n",
    "    y_true = Y[:24*days]\n",
    "    y_pred = Y_h_sd[:24*days]\n",
    "    print('Forecasting accuracy (RMSE) my:',mse_sd)\n",
    "    rmse_sd = mse_sd\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "    #         plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "            plt.plot(predictions_sd.T[i,:24*days],label= 'sd',color='pink')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_sd, _, lst_U_sd, rmse_sd, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mssa(data_train, data_test, rank, L, n_users, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    model = mSSA(rank = rank, normalize = False, L=L)\n",
    "    \n",
    "    # model\n",
    "    model.update_model(data_train)\n",
    "    actual, predictions = predict_one_day(data_test, model, None)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h = predictions.T[:,:]\n",
    "    mse = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h[:24*days])))\n",
    "    y_true = Y[:24*days]\n",
    "    y_pred = Y_h[:24*days]\n",
    "    print ('Forecasting accuracy (RMSE):',mse)\n",
    "    rmse_mssa = mse \n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "            plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h, model.ts_model.models[0].weights, rmse_mssa, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def test_fedMssa(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single, missingVal=0, store=0):    \n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "    # print(f'M_ts: {M_ts}')\n",
    "    # model\n",
    "    model_my = mSSA(rank = dim, normalize = False, L=L)\n",
    "    # model\n",
    "    model_my.update_model(data_train)\n",
    "\n",
    "    # P_admm = flattened_obs\n",
    "\n",
    "    # ====== 2. read personalized U from h5, which is Ui\n",
    "    results_path = f\"results/SSA/mulTS\"\n",
    "    file_name = f\"Elec370_MissingVal{missingVal}_MulTSTrue_N{n_users}_L80_d80.h5\"\n",
    "\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    lst_U = []\n",
    "\n",
    "    # Get the list of local U matrix\n",
    "    import h5py\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        for a_group_key in list(f.keys()):\n",
    "            ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "            lst_U.append(ds_arr)\n",
    "\n",
    "\n",
    "    # Get the list of training data\n",
    "    P_admm = []\n",
    "    for i in range(n_users):\n",
    "        file_name = f'data/data_mulTS/electricity_train_mulTS/electricity_train_nusers_{n_users}_missing_{missingVal}/client_{i}.npy'\n",
    "        client_i_data = np.load(file_name)\n",
    "        P_admm.append(client_i_data)\n",
    "\n",
    "    P_admm = np.array(P_admm)\n",
    "    # print(P_admm.shape)\n",
    "\n",
    "    # Select PCs by Sigma\n",
    "    for i in range(n_users):\n",
    "        proj_admm_i = lst_U[i].T.dot(P_admm[i])\n",
    "        S2_admm_i_est = proj_admm_i.dot(proj_admm_i.T)\n",
    "        S2_admm_i = np.diag(S2_admm_i_est)\n",
    "        S_admm_i = np.sqrt(S2_admm_i)\n",
    "        Uk_admm_i = lst_U[i][:,S_admm_i.argsort()[::-1][:dim]] # 针对每一个client，取Uk的那20列，which 取决于 S_admm的大小\n",
    "        lst_U[i] = Uk_admm_i\n",
    "    # ============================================================\n",
    "    \n",
    "    # Select PCs randomly\n",
    "#     select_idx = np.random.choice(np.arange(L),dim,replace=False)\n",
    "#     lst_U = []\n",
    "#     for i in range(n_users):\n",
    "#         lst_U.append(Uk_admm[:,:dim])\n",
    "#     print(\"Uk shape: \", lst_U[0].shape)\n",
    "\n",
    "    imputation_model_score_admm = []\n",
    "    \n",
    "    P_admm_hat = []\n",
    "    y_admm = []\n",
    "    y_true = P_admm[-1,:]\n",
    "    P_tilde_admm_hat = []\n",
    "    window = M_ts\n",
    "\n",
    "    for i in range(n_users):\n",
    "        P_i_admm = P_admm[i]\n",
    "        P_i_admm_hat = lst_U[i].dot(lst_U[i].T.dot(P_i_admm)); P_admm_hat.append(P_i_admm_hat)\n",
    "        y_i_admm = P_i_admm_hat[-1,:]; y_admm.append(y_i_admm)\n",
    "        y_i_true = P_i_admm[-1,:]\n",
    "        P_i_tilde_admm_hat = P_i_admm_hat[:-1,:]; P_tilde_admm_hat.append(P_i_tilde_admm_hat)\n",
    "        imputation_model_score_admm.append(r2_score(P_i_admm.flatten('F'),P_i_admm_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "        \n",
    "        '''Store data into files if non-exist'''\n",
    "        if store !=0:\n",
    "            # Store imputed data into files\n",
    "            x_file_name = f\"results/imputed_data/mulTS/electricity_nusers_{n_users}_missing_{missingVal}/x_client_{i}.npy\"\n",
    "            y_file_name = f\"results/imputed_data/mulTS/electricity_nusers_{n_users}_missing_{missingVal}/y_client_{i}.npy\"\n",
    "            isExist = os.path.exists(x_file_name)\n",
    "            if not isExist:\n",
    "                imputed_x = copy.deepcopy(P_i_tilde_admm_hat)\n",
    "                imputed_y = copy.deepcopy(y_i_admm)\n",
    "                imputed_x = imputed_x.T\n",
    "                # print(imputed_x.shape)\n",
    "                # print(imputed_y.shape)\n",
    "                np.save(x_file_name, imputed_x)\n",
    "                np.save(y_file_name, imputed_y)\n",
    "            else:\n",
    "                print(f\"X and Y Data of client {i} are created\")\n",
    "\n",
    "            '''Store all x, y data into a matrix which facilitates testing step'''\n",
    "            all_data_file_name = f\"results/imputed_data/mulTS/electricity_nusers_{n_users}_missing_{missingVal}/all_data_client_{i}.npy\"\n",
    "            isExist = os.path.exists(all_data_file_name)\n",
    "            if not isExist:\n",
    "                all_data = copy.deepcopy(P_i_admm_hat)\n",
    "                print(all_data.shape)\n",
    "                np.save(all_data_file_name, all_data)\n",
    "            else:\n",
    "                print(f\"All data for client {i} is created \")\n",
    "\n",
    "    imputation_model_score_admm = np.array(imputation_model_score_admm)\n",
    "\n",
    "    \n",
    "    # matrix contain whole data\n",
    "    imputed_data = P_admm_hat\n",
    "\n",
    "    # Prepare for fitting model\n",
    "    \n",
    "    P_admm_hat = np.hstack(P_admm_hat)\n",
    "    y_admm = np.hstack(y_admm)\n",
    "    P_tilde_admm_hat = np.hstack(P_tilde_admm_hat)\n",
    "    imputed_data = np.array(imputed_data)\n",
    "    print(f\"imputed_data: {imputed_data.shape}\")\n",
    "    print(\"imputation score\", imputation_model_score_admm.mean())\n",
    "\n",
    "    # verify weights_admm using sklearn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg = LinearRegression(fit_intercept=False).fit(P_tilde_admm_hat.T, y_admm)\n",
    "    weights_LR = reg.coef_\n",
    "    \n",
    "    model_my.ts_model.models[0].weights = weights_LR\n",
    "    \n",
    "    actual, predictions_my = predict_one_day(data_test, model_my, weights_LR)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h_my = predictions_my.T[:,:]\n",
    "    mse_my = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_my[:24*days])))\n",
    "    y_true = Y[:24*days]\n",
    "    y_pred = Y_h_my[:24*days]\n",
    "    print ('Forecasting accuracy (RMSE) my:',mse_my)\n",
    "    rmse_fedmssa = mse_my\n",
    "\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,25)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*7],label= 'mSSA',color='green')\n",
    "            plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "        #     plt.plot(predictions_sd[i,:24*7],label= 'sd',color='pink')\n",
    "        #     plt.fill_between(np.arange(24*7), lb[i,:24*7], ub[i,:24*7], alpha = 0.1)\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_my, weights_LR, lst_U, rmse_fedmssa, imputed_data, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25968, 370)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals = create_missing_data(data_train, missing_percentage=0)\n",
    "data_train_missing_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_361</th>\n",
       "      <th>MT_362</th>\n",
       "      <th>MT_363</th>\n",
       "      <th>MT_364</th>\n",
       "      <th>MT_365</th>\n",
       "      <th>MT_366</th>\n",
       "      <th>MT_367</th>\n",
       "      <th>MT_368</th>\n",
       "      <th>MT_369</th>\n",
       "      <th>MT_370</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.298429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.867907</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.711666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.862776</td>\n",
       "      <td>-0.926923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.111780</td>\n",
       "      <td>-0.964607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.312616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.739357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.044284</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.179057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.905502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MT_001    MT_002  MT_003    MT_004    MT_005  MT_006  \\\n",
       "time                                                                        \n",
       "2012-01-01 01:00:00     0.0  0.000000     0.0  0.750556  0.000000     0.0   \n",
       "2012-01-01 02:00:00     0.0 -0.711666     0.0  0.723940  0.000000     0.0   \n",
       "2012-01-01 03:00:00     0.0 -0.739357     0.0  0.000000  0.000000     0.0   \n",
       "2012-01-01 04:00:00     0.0  0.000000     0.0  0.000000  0.037999     0.0   \n",
       "2012-01-01 05:00:00     0.0 -0.905502     0.0  0.000000  0.000000     0.0   \n",
       "\n",
       "                       MT_007  MT_008  MT_009  MT_010  ...    MT_361  MT_362  \\\n",
       "time                                                   ...                     \n",
       "2012-01-01 01:00:00  0.000000     0.0     0.0     0.0  ...  0.000000     0.0   \n",
       "2012-01-01 02:00:00  0.000000     0.0     0.0     0.0  ...  0.000000     0.0   \n",
       "2012-01-01 03:00:00  0.000000     0.0     0.0     0.0  ...  0.000000     0.0   \n",
       "2012-01-01 04:00:00 -0.179057     0.0     0.0     0.0  ...  0.000000     0.0   \n",
       "2012-01-01 05:00:00  0.000000     0.0     0.0     0.0  ... -1.179598     0.0   \n",
       "\n",
       "                       MT_363    MT_364  MT_365    MT_366    MT_367    MT_368  \\\n",
       "time                                                                            \n",
       "2012-01-01 01:00:00  0.000000  0.000000     0.0  0.000000 -0.298429  0.000000   \n",
       "2012-01-01 02:00:00 -0.862776 -0.926923     0.0  0.000000 -0.111780 -0.964607   \n",
       "2012-01-01 03:00:00  0.000000  0.000000     0.0  0.000000  0.000000  0.000000   \n",
       "2012-01-01 04:00:00  0.000000  0.000000     0.0 -0.289139  0.000000  0.000000   \n",
       "2012-01-01 05:00:00  0.000000  0.000000     0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "                       MT_369    MT_370  \n",
       "time                                     \n",
       "2012-01-01 01:00:00 -0.867907 -1.312616  \n",
       "2012-01-01 02:00:00  0.000000 -1.312616  \n",
       "2012-01-01 03:00:00 -1.044284  0.000000  \n",
       "2012-01-01 04:00:00  0.000000  0.000000  \n",
       "2012-01-01 05:00:00  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/home/tung6100/phD/semester3/Federated_MSSA\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_csv_data:\n",
    "    for i in range(data_train_missing_vals.shape[1]):\n",
    "        data_train_missing_vals.iloc[:,i].to_csv('../../data/electricity370_train_missing_80/'+ 'MT_{0:03}'.format(i+1) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "def evaluate_Testset(y_true, y_pred):\n",
    "    def mape(y_true, y_pred): \n",
    "      return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    MSE = mse(y_true, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAE = mae(y_true, y_pred)\n",
    "    MAPE = mape(y_true, y_pred)\n",
    "    return MSE, RMSE, MAE, MAPE\n",
    "\n",
    "def accuracy_Testset(y_true, y_pred):\n",
    "  diff_pred = list()\n",
    "  diff_true = list()\n",
    "  accuracy = 0.\n",
    "  for i in range(len(y_true)-1):\n",
    "      diff_pred.append(y_pred[i+1]-y_pred[i])\n",
    "      diff_true.append(y_true[i+1]-y_true[i])\n",
    "  count = sum(diff_pred[i] * diff_true[i] > 0 for i in range(len(diff_pred)))\n",
    "  accuracy = count/len(diff_pred) * 100\n",
    "  return accuracy\n",
    "\n",
    "# Function to estimate average accuracy for multiple users\n",
    "def average_acc(y_true, y_pred):\n",
    "    n_users = y_true.shape[0]\n",
    "    acc_list = []\n",
    "    for i in range(n_users):\n",
    "        y_true_i = y_true[i]\n",
    "        y_pred_i = y_pred[i]\n",
    "        acc = accuracy_Testset(y_true_i, y_pred_i)\n",
    "        acc_list.append(acc)\n",
    "    acc_np = np.array(acc_list)\n",
    "    # print(acc_np)\n",
    "    avg_acc = np.mean(acc_np)\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test for 20 users, each user contain a time series data:\n",
    "\n",
    "Setting:\n",
    "- 20 users\n",
    "- each global training round select 10% of users\n",
    "- 20% missing values\n",
    "- each user has a time series data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation score: 0.11145829606019454\n",
      "Forecasting accuracy (RMSE) my: 1.057713534136884\n",
      "MSE: 1.1187579202963374, RMSE: 1.057713534136884, MAE: 0.816969316109871, MAPE: 119.06631581711073, acc: 63.22267389340559\n",
      "imputation score: 0.3963538799485603\n",
      "Forecasting accuracy (RMSE) my: 1.0141792304458486\n",
      "MSE: 1.0285595114677335, RMSE: 1.0141792304458486, MAE: 0.7762107108105333, MAPE: 119.16630180291278, acc: 65.19873532068654\n",
      "imputation score: 0.5709721207362977\n",
      "Forecasting accuracy (RMSE) my: 1.01885629318847\n",
      "MSE: 1.0380681461697494, RMSE: 1.01885629318847, MAE: 0.7770228074380676, MAPE: 142.59230997894068, acc: 61.054652213188795\n",
      "imputation score: 0.7010735667643211\n",
      "Forecasting accuracy (RMSE) my: 1.0353659247745157\n",
      "MSE: 1.071982598184188, RMSE: 1.0353659247745157, MAE: 0.7865839828533664, MAPE: 157.63942794979133, acc: 59.43992773261065\n",
      "imputation score: 0.9734863101026874\n",
      "Forecasting accuracy (RMSE) my: 4832832.437766031\n",
      "MSE: 23356269371523.56, RMSE: 4832832.437766031, MAE: 91649.49336342048, MAPE: 44682943.389992505, acc: 51.82926829268293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.057713534136884,\n",
       " 1.0141792304458486,\n",
       " 1.01885629318847,\n",
       " 1.0353659247745157,\n",
       " 4832832.437766031]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sd = []\n",
    "for dim in [1,10,20,30,70]:\n",
    "    Y1, Y_sd, weights_sd, lst_U_sd, rmse, y_true_sd, y_pred_sd = test_sd(data_train_missing_vals, data_test, L=L, n_users=370, M_ts=window, dim=dim, days=1, plot_all=False, plot_single=False)\n",
    "    MSE, RMSE, MAE, MAPE = evaluate_Testset(y_true_sd, y_pred_sd)\n",
    "    acc = average_acc(y_true_sd, y_pred_sd)\n",
    "    print(f\"MSE: {MSE}, RMSE: {RMSE}, MAE: {MAE}, MAPE: {MAPE}, acc: {acc}\")\n",
    "    \n",
    "    rmse_sd.append(rmse)\n",
    "rmse_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting accuracy (RMSE): 1.062148402719172\n",
      "MSE: 1.1281592293988887, RMSE: 1.062148402719172, MAE: 0.82233310842391, MAPE: 113.84573303917259, acc: 69.20731707317073\n",
      "Forecasting accuracy (RMSE): 0.9373655704120395\n",
      "MSE: 0.8786542125938882, RMSE: 0.9373655704120395, MAE: 0.7166700309683344, MAPE: 105.29179667310385, acc: 70.67524841915086\n",
      "Forecasting accuracy (RMSE): 0.9362289868471185\n",
      "MSE: 0.876524715812782, RMSE: 0.9362289868471185, MAE: 0.7155246240310943, MAPE: 105.39282497526384, acc: 70.69783197831978\n",
      "Forecasting accuracy (RMSE): 0.9344902967535212\n",
      "MSE: 0.8732721147264844, RMSE: 0.9344902967535214, MAE: 0.7138703541245401, MAPE: 108.05025177975016, acc: 70.04290876242096\n",
      "Forecasting accuracy (RMSE): 1.0606053269783293\n",
      "MSE: 1.1248836596148084, RMSE: 1.060605326978329, MAE: 0.8013266321832204, MAPE: 254.46042730221797, acc: 56.18789521228546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.062148402719172,\n",
       " 0.9373655704120395,\n",
       " 0.9362289868471185,\n",
       " 0.9344902967535212,\n",
       " 1.0606053269783293]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_mssa = []\n",
    "for rank in [1,10,20,30,70]:\n",
    "    Y2, Y_mssa, weights_mssa, rmse, y_true_mssa, y_pred_mssa = test_mssa(data_train_missing_vals, data_test, rank=rank, L=L, n_users=370, days=1, plot_all=False, plot_single=False)\n",
    "    MSE, RMSE, MAE, MAPE = evaluate_Testset(y_true_mssa, y_pred_mssa)\n",
    "    acc = average_acc(y_true_mssa, y_pred_mssa)\n",
    "    print(f\"MSE: {MSE}, RMSE: {RMSE}, MAE: {MAE}, MAPE: {MAPE}, acc: {acc}\")\n",
    "    rmse_mssa.append(rmse)\n",
    "rmse_mssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/home/tung6100/phD/semester3/Federated_MSSA\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/home/tung6100\n",
      "/share/home/tung6100/phD/semester3/Federated_MSSA\n"
     ]
    }
   ],
   "source": [
    "%cd \n",
    "%cd phD/semester3/Federated_MSSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.30016966526234135\n",
      "Forecasting accuracy (RMSE) my: 0.8746662833563111\n",
      "MSE: 0.7650411072403426, RMSE: 0.874666283356311, MAE: 0.658047994659515, MAPE: 257.38274330459916, acc: 72.54901960784314\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.6834576066004395\n",
      "Forecasting accuracy (RMSE) my: 2.197254766656587\n",
      "MSE: 4.827928509595092, RMSE: 2.197254766656587, MAE: 1.6633949025544383, MAPE: 511.56468303460434, acc: 67.6470588235294\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.7877430240871156\n",
      "Forecasting accuracy (RMSE) my: 0.6930682927859735\n",
      "MSE: 0.48034365846526383, RMSE: 0.6930682927859735, MAE: 0.49064192983864696, MAPE: 139.75496208406005, acc: 77.45098039215686\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.8499214667725618\n",
      "Forecasting accuracy (RMSE) my: 0.5558235537600051\n",
      "MSE: 0.3089398229144013, RMSE: 0.5558235537600051, MAE: 0.3942868323764421, MAPE: 161.54329266522504, acc: 83.08823529411764\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.8952791881165368\n",
      "Forecasting accuracy (RMSE) my: 0.50632070741704\n",
      "MSE: 0.25636065875929187, RMSE: 0.50632070741704, MAE: 0.34764862129617347, MAPE: 120.0291904647273, acc: 84.06862745098039\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.9314786658854791\n",
      "Forecasting accuracy (RMSE) my: 0.43076296410049497\n",
      "MSE: 0.18555673124064434, RMSE: 0.43076296410049497, MAE: 0.3016721568692237, MAPE: 93.20963982352416, acc: 85.04901960784314\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.960108386763269\n",
      "Forecasting accuracy (RMSE) my: 0.3930162759889132\n",
      "MSE: 0.15446179319219355, RMSE: 0.39301627598891314, MAE: 0.27959459770735356, MAPE: 66.95831276549534, acc: 87.00980392156862\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.9828468688537456\n",
      "Forecasting accuracy (RMSE) my: 0.3762538046321915\n",
      "MSE: 0.14156692550019934, RMSE: 0.3762538046321915, MAE: 0.26491494530145027, MAPE: 65.05739889794812, acc: 87.00980392156862\n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 1.0\n",
      "Forecasting accuracy (RMSE) my: 0.3513340287598636\n",
      "MSE: 0.12343559976463665, RMSE: 0.3513340287598636, MAE: 0.24247641418212526, MAPE: 68.29829416051851, acc: 87.74509803921569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8746662833563111,\n",
       " 2.197254766656587,\n",
       " 0.6930682927859735,\n",
       " 0.5558235537600051,\n",
       " 0.50632070741704,\n",
       " 0.43076296410049497,\n",
       " 0.3930162759889132,\n",
       " 0.3762538046321915,\n",
       " 0.3513340287598636]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_fedmssa = []\n",
    "for dim in [1,10,20,30, 40, 50, 60, 70, 80]:\n",
    "    Y3, Y_my, weights_my, lst_U_my, rmse, imputed_data, y_true, y_pred = test_fedMssa(data_train_missing_vals, data_test, L=L, n_users=18, M_ts=window, dim=dim, days=1, plot_all=False, plot_single=False, missingVal=0, store=0)\n",
    "    MSE, RMSE, MAE, MAPE = evaluate_Testset(y_true, y_pred)\n",
    "    acc = average_acc(y_true, y_pred)\n",
    "    print(f\"MSE: {MSE}, RMSE: {RMSE}, MAE: {MAE}, MAPE: {MAPE}, acc: {acc}\")\n",
    "    rmse_fedmssa.append(rmse)\n",
    "rmse_fedmssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = os.getcwd()\n",
    "# results_folder_path = os.path.join(directory, \"rmse\")\n",
    "# sd_file_name = \"sd_rmse_80_missing_20\"\n",
    "# mssa_file_name = \"mssa_rmse_80_missing_20\"\n",
    "# fedmssa_file_name = \"fedmssa_rmse_80_missing_20\"\n",
    "# sd_path = os.path.join(results_folder_path, sd_file_name)\n",
    "# mssa_path = os.path.join(results_folder_path, mssa_file_name)\n",
    "# fedmssa_path = os.path.join(results_folder_path, fedmssa_file_name)\n",
    "# rmse_sd_np = np.array(rmse_sd)\n",
    "# rmse_mssa_np = np.array(rmse_mssa)\n",
    "# rmse_fedmssa_np = np.array(rmse_fedmssa)\n",
    "# np.save(sd_path, rmse_sd_np)\n",
    "# np.save(mssa_path, rmse_mssa_np)\n",
    "# np.save(fedmssa_path, rmse_fedmssa_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  sd\n",
    "# x = range(1, 30)\n",
    "# plt.plot(x, rmse_sd_np[:29])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  mssa\n",
    "# x = range(1, 30)\n",
    "# plt.plot(x, rmse_mssa_np[:29])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE vs dim  fedmssa\n",
    "# x = range(1, 31)\n",
    "# plt.plot(x, rmse_fedmssa_np[50:80])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = range(1, 31)\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# rmse_sd_best = rmse_sd_np[:30]\n",
    "# rmse_mssa_best = rmse_mssa_np[:30]\n",
    "# rmse_fedmssa_best = rmse_fedmssa_np[50:80]\n",
    "# plt.plot(x, rmse_sd_best, label=\"standalone ssa\")\n",
    "# plt.plot(x, rmse_mssa_best, label=\"centralized mssa\")\n",
    "# plt.plot(x, rmse_fedmssa_best, label=\"fedmssa\")\n",
    "# plt.title(\"RMSE\")\n",
    "# plt.legend(prop={'size': 20})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test for 370 users, each user contain a time series data:\n",
    "\n",
    "Setting:\n",
    "- 370 users\n",
    "- each global training round select 10% of users\n",
    "- 20% missing values\n",
    "- each user has a time series data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dim in [1]:\n",
    "#     Y1, Y_sd, weights_sd, lst_U_sd = test_sd(data_train_missing_vals, data_test, L=80, n_users=370, M_ts=window, dim=10, days=2, plot_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rank in [15]:\n",
    "#     Y2, Y_mssa, weights_mssa = test_mssa(data_train_missing_vals, data_test, rank=10, L=80, n_users=370, days=2, plot_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y3, Y_my, weights_my, lst_U_my = test_fedMssa(data_train, data_test, L=80, n_users=370, M_ts=window, dim=74, days=2, plot_all=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get imputed data from FedMSSA and Store as file for FedLSTM\n",
    "\n",
    "## Best rank for Electricity Dataset:\n",
    "- Missing percentage:  0% - rank: 70\n",
    "- Missing percentage: 20% - rank: 50\n",
    "- Missing percentage: 40% - rank: 40 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y Data of client 0 are created\n",
      "All data for client 0 is created \n",
      "X and Y Data of client 1 are created\n",
      "All data for client 1 is created \n",
      "X and Y Data of client 2 are created\n",
      "All data for client 2 is created \n",
      "X and Y Data of client 3 are created\n",
      "All data for client 3 is created \n",
      "X and Y Data of client 4 are created\n",
      "All data for client 4 is created \n",
      "X and Y Data of client 5 are created\n",
      "All data for client 5 is created \n",
      "X and Y Data of client 6 are created\n",
      "All data for client 6 is created \n",
      "X and Y Data of client 7 are created\n",
      "All data for client 7 is created \n",
      "X and Y Data of client 8 are created\n",
      "All data for client 8 is created \n",
      "X and Y Data of client 9 are created\n",
      "All data for client 9 is created \n",
      "X and Y Data of client 10 are created\n",
      "All data for client 10 is created \n",
      "X and Y Data of client 11 are created\n",
      "All data for client 11 is created \n",
      "X and Y Data of client 12 are created\n",
      "All data for client 12 is created \n",
      "X and Y Data of client 13 are created\n",
      "All data for client 13 is created \n",
      "X and Y Data of client 14 are created\n",
      "All data for client 14 is created \n",
      "X and Y Data of client 15 are created\n",
      "All data for client 15 is created \n",
      "X and Y Data of client 16 are created\n",
      "All data for client 16 is created \n",
      "X and Y Data of client 17 are created\n",
      "All data for client 17 is created \n",
      "imputed_data: (18, 80, 6480)\n",
      "imputation score 0.9828468688537456\n",
      "Forecasting accuracy (RMSE) my: 0.3762538046321915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18, 80, 6480)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get imputed data from the FedMSSA with the best rank (=30 for example)\n",
    "Y3, Y_my, weights_my, lst_U_my, rmse, imputed_data, y_true, y_pred = test_fedMssa(data_train_missing_vals, data_test, L=L, n_users=18, M_ts=window, dim=70, days=1, plot_all=False, plot_single=False, missingVal=0, store=1)\n",
    "\n",
    "imputed_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 80, 324)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert imputed data to an array\n",
    "imputed_data_np = np.array(imputed_data)\n",
    "imputed_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25920)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten page matrix\n",
    "imputed_data_flatten = []\n",
    "for user in imputed_data_np:\n",
    "  user_data = user.flatten('F')\n",
    "  imputed_data_flatten.append(user_data)\n",
    "imputed_data_flatten_np = np.array(imputed_data_flatten)\n",
    "imputed_data_flatten_np.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make comparison between imputed data and original data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25968)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the original data train\n",
    "ts_data_train = data_train.T\n",
    "ts_data_train = ts_data_train.to_numpy()\n",
    "ts_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25920,)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 2\n",
    "# Get actual data for a user to test\n",
    "actual_data_client = ts_data_train[user_id]\n",
    "actual_data_client = actual_data_client[-25920:]\n",
    "actual_data_client.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25920,)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get imputed data for corresponding user\n",
    "imputed_data_client = imputed_data_flatten_np[user_id]\n",
    "imputed_data_client.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize original data\n",
    "plt.plot(actual_data_client, label=\"actual\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize original data\n",
    "plt.plot(imputed_data_client, label=\"imputed\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the imputed data for FedLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store the imputed data\n",
    "def store_imputed_data(n_users, L, dim, missing_percentage, imputed_data):\n",
    "    results_path = f\"../imputed_data/\"\n",
    "    file_name = f\"numuser_{n_users}_L_{L}_dim_{dim}_missingPercentage_{missing_percentage}\"\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    np.save(file_path, imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store imputed data\n",
    "store_imputed_data = False\n",
    "if store_imputed_data:\n",
    "    store_imputed_data(n_users=20, L=80, dim=40, missing_percentage=40, imputed_data=imputed_data_flatten_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
