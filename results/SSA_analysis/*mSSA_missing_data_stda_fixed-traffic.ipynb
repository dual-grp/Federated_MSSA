{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mssa.mssa import mSSA\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import io\n",
    "import numpy as np \n",
    "import torch \n",
    "import copy \n",
    "from sklearn.metrics import r2_score\n",
    "import os \n",
    "from datetime import datetime, timedelta\n",
    "from datetime import timedelta\n",
    "dev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"traffic.txt\"\n",
    "isExist = os.path.exists(file)\n",
    "if not isExist:\n",
    "    print(f\"Files not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded..\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Preprocess data\"\"\"\n",
    "data = pd.read_csv('traffic.txt', delimiter = ',', header=None)\n",
    "print('data loaded..')\n",
    "data_2 = data.copy()\n",
    "#pick the first 20 clients\n",
    "data_2 = data_2.iloc[:,:20]\n",
    "#create time column: 2 years 1 hour\n",
    "data_2['time'] = pd.to_datetime(np.arange(datetime(2015,1,1), datetime(2017,1,1), timedelta(hours=1)))\n",
    "data_2.index = data_2['time']\n",
    "data_2 = data_2.drop(['time'], axis = 1)\n",
    "#create column names\n",
    "data_3 = data_2.copy()\n",
    "col_names = ['MT_{0:03}'.format(i+1) for i in range(data_3.shape[1])]\n",
    "data_3.columns = col_names\n",
    "aggregated_data = data_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17544, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "Std_normalization = 1\n",
    "if Std_normalization:\n",
    "    scaler = StandardScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "    norm_means = scaler.mean_\n",
    "    norm_std = scaler.scale_\n",
    "else:\n",
    "    scaler = MinMaxScaler()\n",
    "    temp = scaler.fit_transform(aggregated_data)\n",
    "global data_4\n",
    "normalized_data = pd.DataFrame(temp, index=aggregated_data.index, columns = aggregated_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>-0.936348</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>-0.569033</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>-0.660995</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>-0.914064</td>\n",
       "      <td>-0.568700</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>-0.488945</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>-0.407787</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.514071</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>-0.901844</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>-0.826841</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>-0.672342</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>-0.810024</td>\n",
       "      <td>-0.959996</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>-0.923742</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>-1.321309</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>-1.233545</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143 -0.936348 -1.154807 -0.569033   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168 -0.826841 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566 -0.660995 -0.414196   \n",
       "2015-01-01 01:00:00 -0.488945 -0.701394 -0.490022 -0.447094 -0.407787   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00 -0.672342 -0.886640 -0.810024 -0.959996 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473 -0.914064 -0.568700 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055 -0.901844 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059 -0.923742 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622 -1.233545   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432 -0.748872 -0.514071 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993 -1.321309 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    cols = normalized_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    test_df = normalized_data.iloc[:5][cols[:5]].copy()\n",
    "    np_test = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    \"\"\"Inject missing data\"\"\"\n",
    "    # Convert original data to 1d array - Because existing package only supports randomly choose from 1d array\n",
    "    np_test_1d = np_test.flatten()\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    total_elem = np_test_1d.shape[0]\n",
    "    missing_percentage = 50\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100) \n",
    "    print(number_of_missing_elem)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False)\n",
    "    np_test_1d[missing_index] = 0\n",
    "    np_test_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dev:\n",
    "    np_test_2d = np_test_1d.reshape(5,-1)\n",
    "    np_test_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143  0.000000 -1.154807  0.000000   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168  0.000000 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566  0.000000 -0.414196   \n",
       "2015-01-01 01:00:00  0.000000 -0.701394 -0.490022 -0.447094  0.000000   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00  0.000000 -0.886640  0.000000  0.000000 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473  0.000000  0.000000 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055  0.000000 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059  0.000000 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622  0.000000   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432  0.000000  0.000000 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993  0.000000 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Create missing values based on normal distribution random choice\n",
    "\n",
    "Input: \n",
    " - pd_data: 2d pandas data frame\n",
    " - missing_percentage: missing percentage <= 100\n",
    "\n",
    "Output:\n",
    " - return_data: 2d pandas with missed values\n",
    "\n",
    "\"\"\"\n",
    "def create_missing_data(pd_data, missing_percentage = 20):\n",
    "    if missing_percentage == 0: return pd_data\n",
    "    assert missing_percentage <= 100, \"missing percentage should be less than or equal 100%\"\n",
    "    np.random.seed(1993)\n",
    "    # Convert data frame to array\n",
    "    np_data = pd_data.to_numpy()\n",
    "    # Convert original data to 1d array - Because existing package only supports to randomly choose indices from 1d array\n",
    "    np_data_1d = np_data.flatten()\n",
    "    # Randomly choose missing index\n",
    "    total_elem = np_data_1d.shape[0]\n",
    "    number_of_missing_elem = int(missing_percentage*1.0*total_elem/100)\n",
    "    missing_index = np.random.choice(np.arange(total_elem), number_of_missing_elem, replace=False) # with replace = False, an index only is chosen 1 time\n",
    "    # Replace missing_index with 0\n",
    "    np_data_1d[missing_index] = 0\n",
    "    # Convert 1d array to 2d array\n",
    "    np_data_2d = np_data_1d.reshape(pd_data.shape[0], pd_data.shape[1])\n",
    "    # Convert 2d array to dataframe\n",
    "    cols_name = pd_data.columns\n",
    "    return_data = pd.DataFrame(np_data_2d, columns = cols_name)\n",
    "    return_data.index = pd_data.index\n",
    "    return return_data\n",
    "\n",
    "missing_df = create_missing_data(normalized_data, missing_percentage=20)\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global n_clients; global data_train; global data_test\n",
    "def set_train_test(n_clients=20):\n",
    "    data_train = normalized_data.iloc[:17376,:n_clients] \n",
    "    data_test = normalized_data.iloc[17376:,:n_clients]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17376, 20)\n",
      "(168, 20)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = set_train_test(n_clients=20)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_obs(data_train, L=80):\n",
    "    df = data_train\n",
    "    N = df.shape[1]\n",
    "#     col_to_row_ratio = 4\n",
    "\n",
    "    T = df.shape[0]\n",
    "\n",
    "    M = int(df.size / L)\n",
    "    if M%N != 0:\n",
    "        M -= M%N\n",
    "    M_ts = M // N\n",
    "    # inc_obs = np.array(df.iloc[:M_ts*L,:]) # first range, we use second range for traning\n",
    "    inc_obs = np.array(df.iloc[T%L:,:]) # second range, note its not T%L+1 due to python index\n",
    "    normalize = False\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        inc_obs = scaler.fit_transform(inc_obs)\n",
    "        norm_means = scaler.mean_\n",
    "        norm_std = scaler.scale_\n",
    "\n",
    "    flattened_obs = inc_obs.reshape([L,M], order = 'F') # 按照列顺序\n",
    "    # flattened_obs = flattened_obs[:,np.arange(M_ts*self.no_ts).reshape([self.no_ts,M_ts]).flatten('F')] # 这里导致第二列是ts2，stacked page是不同ts交错组成\n",
    "    return flattened_obs, M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global N; global M_ts; global L; global window\n",
    "L = 100\n",
    "flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "window = M_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_day(data_test, model, weights, days=7):\n",
    "    # predict for seven days\n",
    "    # days = 7\n",
    "\n",
    "    #initialise prediction array\n",
    "    predictions = np.zeros((len(data_test.columns),24*days))\n",
    "    ub = np.zeros((len(data_test.columns),24*days))\n",
    "    lb = np.zeros((len(data_test.columns),24*days))\n",
    "\n",
    "    # specify start time\n",
    "    start_time = pd.Timestamp('2016-12-25 00:00:00')\n",
    "\n",
    "    # actual = data_test.values[:24*days,:]\n",
    "\n",
    "    # obtain new actual by index, new test start from 2014-12-02-17:00\n",
    "    actual = data_test[data_test.index>=start_time].values[:24*days,:]\n",
    "\n",
    "\n",
    "    for day in range(days):\n",
    "        # get the final time stamp in the day\n",
    "        end_time = start_time + pd.Timedelta(hours=23)\n",
    "        # convert timestamps to string\n",
    "        start_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # predict for each house\n",
    "        for i, column in enumerate(data_test.columns):\n",
    "            # Forecast\n",
    "            df_30 = model.predict(column,start_str,end_str)\n",
    "            predictions[i,day*24:(day+1)*24] = df_30['Mean Predictions']\n",
    "            ub[i,day*24:(day+1)*24] = df_30['Upper Bound']\n",
    "            lb[i,day*24:(day+1)*24] = df_30['Lower Bound']\n",
    "\n",
    "        # fit the model with the already predicted values \n",
    "\n",
    "        # df_insert = data_test.iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # obtain new df_insert\n",
    "        # df_insert = data_test[data_test.index>=start_time].iloc[day*24:24*(day+1),:]\n",
    "\n",
    "        # model.update_model(df_insert)\n",
    "    \n",
    "        if weights is not None:\n",
    "            model.ts_model.models[0].weights = weights\n",
    "\n",
    "        # update start_time\n",
    "        start_time = start_time + pd.Timedelta(hours=24)\n",
    "    return actual, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sd(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users] # Debug1\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "    # stand-alone ssa\n",
    "    window = M_ts\n",
    "    lst_U_sd = []\n",
    "    for i in range(n_users):\n",
    "        data = flattened_obs[:,i*window:(i+1)*window]\n",
    "        U,_,_ = np.linalg.svd(data)\n",
    "        U = U[:,:dim]\n",
    "        lst_U_sd.append(U)\n",
    "\n",
    "    P_sd = flattened_obs\n",
    "    P_sd_hat = []\n",
    "    y_sd = []\n",
    "    y_true = P_sd[-1,:]\n",
    "    P_tilde_sd_hat = []\n",
    "    imputation_model_score_sd = []\n",
    "    actual = []; predictions_sd = []\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        P_i_sd = P_sd[:,int(i*window):int((i+1)*window)]\n",
    "        P_i_sd_hat = lst_U_sd[i].dot(lst_U_sd[i].T.dot(P_i_sd)); P_sd_hat.append(P_i_sd_hat)\n",
    "        y_i_sd = P_i_sd_hat[-1,:]; y_sd.append(y_i_sd)\n",
    "        y_i_true = P_i_sd[-1,:]\n",
    "        P_i_tilde_sd_hat = P_i_sd_hat[:-1,:]; P_tilde_sd_hat.append(P_i_tilde_sd_hat)\n",
    "        imputation_model_score_sd.append(r2_score(P_i_sd.flatten('F'),P_i_sd_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "        # prediction\n",
    "        reg = LinearRegression(fit_intercept=False).fit(P_i_tilde_sd_hat.T, y_i_sd)\n",
    "        weights_sd_i = reg.coef_\n",
    "        model_sd = mSSA(rank = dim, normalize = False, L=L)\n",
    "        model_sd.update_model(pd.DataFrame(data_train.iloc[:,i]))\n",
    "        model_sd.ts_model.models[0].weights = weights_sd_i\n",
    "        actual_i, predictions_sd_i = predict_one_day(pd.DataFrame(data_test.iloc[:,i]), model_sd, weights_sd_i)\n",
    "        actual.append(actual_i); predictions_sd.append(predictions_sd_i.T)\n",
    "    imputation_model_score_sd = np.array(imputation_model_score_sd)\n",
    "    P_sd_hat = np.hstack(P_sd_hat)\n",
    "    y_sd = np.hstack(y_sd)\n",
    "    P_tilde_sd_hat = np.hstack(P_tilde_sd_hat)\n",
    "    actual = np.hstack(actual); predictions_sd = np.hstack(predictions_sd)\n",
    "    print(\"imputation score:\", imputation_model_score_sd.mean())\n",
    "    \n",
    "    Y = actual[:,:]\n",
    "    Y_h_sd = predictions_sd[:,:]\n",
    "    mse_sd = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_sd[:24*days]))) # Debug2\n",
    "    y_true = Y[:24*days]\n",
    "    y_pred = Y_h_sd[:24*days]\n",
    "    print('Forecasting accuracy (RMSE) my:',mse_sd)\n",
    "    rmse_sd = mse_sd\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "    #         plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "            plt.plot(predictions_sd.T[i,:24*days],label= 'sd',color='pink')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_sd, _, lst_U_sd, rmse_sd, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mssa(data_train, data_test, rank, L, n_users, days, plot_all, plot_single):\n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    model = mSSA(rank = rank, normalize = False, L=L)\n",
    "    \n",
    "    # model\n",
    "    model.update_model(data_train)\n",
    "    actual, predictions = predict_one_day(data_test, model, None)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h = predictions.T[:,:]\n",
    "    mse = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h[:24*days])))\n",
    "    y_true = Y[:24*days]\n",
    "    y_pred = Y_h[:24*days]\n",
    "    print ('Forecasting accuracy (RMSE):',mse)\n",
    "    rmse_mssa = mse \n",
    "    if plot_all:\n",
    "        npar = np.arange(0,20)\n",
    "    else: npar = [1]\n",
    "\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "            plt.plot(predictions[i,:24*days],label= 'mSSA',color='green')\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h, model.ts_model.models[0].weights, rmse_mssa, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fedMssa(data_train, data_test, L, n_users, M_ts, dim, days, plot_all, plot_single, missingVal=1):\n",
    "    suffix_missingVal = 'missingVal' if missingVal else 'fullObs'\n",
    "    \n",
    "    data_train = data_train.iloc[:,:n_users]\n",
    "    data_test = data_test.iloc[:,:n_users]\n",
    "    flattened_obs, M_ts = get_flattened_obs(data_train, L=L)\n",
    "\n",
    "    # model\n",
    "    model_my = mSSA(rank = dim, normalize = False, L=L)\n",
    "    # model\n",
    "    model_my.update_model(data_train)\n",
    "\n",
    "    P_admm = flattened_obs\n",
    "    # ============================================================\n",
    "    # ====== 1. read common U from npy, which is Z\n",
    "#     results_path = f\"../SSA/\"\n",
    "#     file_name = f\"Grassmann_ADMM_constraint2_Traffic{n_users}_{suffix_missingVal}_N{n_users}_L{L}_d{L}_rhoauto_imputation.npy\"\n",
    "#     file_path = os.path.join(results_path, file_name)\n",
    "#     Uk_admm = np.load(file_path)\n",
    "#     # Select PCs by Sigma\n",
    "#     lst_U = []\n",
    "#     for i in range(n_users):\n",
    "#         proj_admm_i = Uk_admm.T.dot(P_admm[:,i*M_ts:(i+1)*M_ts])\n",
    "#         S2_admm_i_est = proj_admm_i.dot(proj_admm_i.T)\n",
    "#         S2_admm_i = np.diag(S2_admm_i_est)\n",
    "#         S_admm_i = np.sqrt(S2_admm_i)\n",
    "#         Uk_admm_i = Uk_admm[:,S_admm_i.argsort()[::-1][:dim]] # 针对每一个client，取Uk的那20列，which 取决于 S_admm的大小\n",
    "#         lst_U.append(Uk_admm_i)\n",
    "    # ============================================================\n",
    "        \n",
    "    # ============================================================\n",
    "    # ====== 2. read personalized U from h5, which is Ui\n",
    "    results_path = f\"../SSA/\"\n",
    "    file_name = f\"Grassmann_ADMM_constraint2_Traffic{n_users}_{suffix_missingVal}20_N{n_users}_L{L}_d{L}_rhoauto_imputation.h5\"\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    lst_U = []\n",
    "    import h5py\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        # Print all root level object names (aka keys) \n",
    "        # these can be group or dataset names \n",
    "#         print(\"Keys: %s\" % f.keys())\n",
    "        # get first object name/key; may or may NOT be a group\n",
    "        for a_group_key in list(f.keys()):\n",
    "            ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "            lst_U.append(ds_arr)\n",
    "    # Select PCs by Sigma\n",
    "    for i in range(n_users):\n",
    "        proj_admm_i = lst_U[i].T.dot(P_admm[:,i*M_ts:(i+1)*M_ts])\n",
    "        S2_admm_i_est = proj_admm_i.dot(proj_admm_i.T)\n",
    "        S2_admm_i = np.diag(S2_admm_i_est)\n",
    "        S_admm_i = np.sqrt(S2_admm_i)\n",
    "        Uk_admm_i = lst_U[i][:,S_admm_i.argsort()[::-1][:dim]] # 针对每一个client，取Uk的那20列，which 取决于 S_admm的大小\n",
    "        lst_U[i] = Uk_admm_i\n",
    "    # ============================================================\n",
    "    \n",
    "    # Select PCs randomly\n",
    "#     select_idx = np.random.choice(np.arange(L),dim,replace=False)\n",
    "#     lst_U = []\n",
    "#     for i in range(n_users):\n",
    "#         lst_U.append(Uk_admm[:,:dim])\n",
    "#     print(\"Uk shape: \", lst_U[0].shape)\n",
    "\n",
    "    imputation_model_score_admm = []\n",
    "    \n",
    "    P_admm_hat = []\n",
    "    y_admm = []\n",
    "    y_true = P_admm[-1,:]\n",
    "    P_tilde_admm_hat = []\n",
    "    window = M_ts\n",
    "    for i in range(n_users):\n",
    "        P_i_admm = P_admm[:,int(i*window):int((i+1)*window)]\n",
    "        P_i_admm_hat = lst_U[i].dot(lst_U[i].T.dot(P_i_admm)); P_admm_hat.append(P_i_admm_hat)\n",
    "        y_i_admm = P_i_admm_hat[-1,:]; y_admm.append(y_i_admm)\n",
    "        y_i_true = P_i_admm[-1,:]\n",
    "        P_i_tilde_admm_hat = P_i_admm_hat[:-1,:]; P_tilde_admm_hat.append(P_i_tilde_admm_hat)\n",
    "        imputation_model_score_admm.append(r2_score(P_i_admm.flatten('F'),P_i_admm_hat.flatten('F'))) # verified same as imputation_model_score)\n",
    "    imputation_model_score_admm = np.array(imputation_model_score_admm)\n",
    "    imputed_data = P_admm_hat\n",
    "    P_admm_hat = np.hstack(P_admm_hat)\n",
    "    y_admm = np.hstack(y_admm)\n",
    "    P_tilde_admm_hat = np.hstack(P_tilde_admm_hat)\n",
    "\n",
    "    print(\"imputation score\", imputation_model_score_admm.mean())\n",
    "\n",
    "    # verify weights_admm using sklearn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg = LinearRegression(fit_intercept=False).fit(P_tilde_admm_hat.T, y_admm)\n",
    "    weights_LR = reg.coef_\n",
    "    \n",
    "    model_my.ts_model.models[0].weights = weights_LR\n",
    "    \n",
    "    actual, predictions_my = predict_one_day(data_test, model_my, weights_LR)\n",
    "\n",
    "    Y = actual[:,:]\n",
    "    Y_h_my = predictions_my.T[:,:]\n",
    "    mse_my = np.sqrt(np.mean(np.square(Y[:24*days]-Y_h_my[:24*days])))\n",
    "    print ('Forecasting accuracy (RMSE) my:',mse_my)\n",
    "    rmse_fedmssa = mse_my\n",
    "\n",
    "    if plot_all:\n",
    "        npar = np.arange(0,25)\n",
    "    else: npar = [1]\n",
    "    if plot_single:\n",
    "        for i in npar:\n",
    "            plt.figure()\n",
    "            plt.title('forecasting the next seven days for %s'%data_test.columns[i])\n",
    "    #         plt.plot(predictions[i,:24*7],label= 'mSSA',color='green')\n",
    "            plt.plot(predictions_my[i,:24*days],label= 'FedmSSA',color='orange')\n",
    "        #     plt.plot(predictions_sd[i,:24*7],label= 'sd',color='pink')\n",
    "        #     plt.fill_between(np.arange(24*7), lb[i,:24*7], ub[i,:24*7], alpha = 0.1)\n",
    "            plt.plot(actual[:24*days,i],label = 'actual',color='blue')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return Y, Y_h_my, weights_LR, lst_U, rmse_fedmssa, imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17376, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals = create_missing_data(data_train, missing_percentage=20)\n",
    "data_train_missing_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>MT_011</th>\n",
       "      <th>MT_012</th>\n",
       "      <th>MT_013</th>\n",
       "      <th>MT_014</th>\n",
       "      <th>MT_015</th>\n",
       "      <th>MT_016</th>\n",
       "      <th>MT_017</th>\n",
       "      <th>MT_018</th>\n",
       "      <th>MT_019</th>\n",
       "      <th>MT_020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.649143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.154807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500971</td>\n",
       "      <td>-0.765328</td>\n",
       "      <td>-0.665566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414196</td>\n",
       "      <td>-0.822551</td>\n",
       "      <td>-0.854473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.899862</td>\n",
       "      <td>-0.569866</td>\n",
       "      <td>-1.335692</td>\n",
       "      <td>-0.748872</td>\n",
       "      <td>-0.798016</td>\n",
       "      <td>-0.608055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>-0.674341</td>\n",
       "      <td>-0.645010</td>\n",
       "      <td>-0.862140</td>\n",
       "      <td>-1.067719</td>\n",
       "      <td>-0.513278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.701394</td>\n",
       "      <td>-0.490022</td>\n",
       "      <td>-0.447094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.770593</td>\n",
       "      <td>-0.822892</td>\n",
       "      <td>-0.849406</td>\n",
       "      <td>-0.507760</td>\n",
       "      <td>-0.835587</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>-1.213432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.599583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>-0.725568</td>\n",
       "      <td>-0.742124</td>\n",
       "      <td>-0.963111</td>\n",
       "      <td>-1.203794</td>\n",
       "      <td>-0.610849</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.822705</td>\n",
       "      <td>-0.641794</td>\n",
       "      <td>-0.681695</td>\n",
       "      <td>-0.484698</td>\n",
       "      <td>-0.886055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.951011</td>\n",
       "      <td>-0.735623</td>\n",
       "      <td>-1.053028</td>\n",
       "      <td>-0.145701</td>\n",
       "      <td>-1.310521</td>\n",
       "      <td>-0.952812</td>\n",
       "      <td>-0.716423</td>\n",
       "      <td>-0.691364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>-0.727168</td>\n",
       "      <td>-0.826841</td>\n",
       "      <td>-1.022720</td>\n",
       "      <td>-1.296324</td>\n",
       "      <td>-0.666604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.886640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602201</td>\n",
       "      <td>-1.015951</td>\n",
       "      <td>-0.929478</td>\n",
       "      <td>-1.023059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.177476</td>\n",
       "      <td>-0.839993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.093459</td>\n",
       "      <td>-0.977522</td>\n",
       "      <td>-0.729489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>-0.722366</td>\n",
       "      <td>-0.837172</td>\n",
       "      <td>-1.055566</td>\n",
       "      <td>-1.318096</td>\n",
       "      <td>-0.680543</td>\n",
       "      <td>-0.706917</td>\n",
       "      <td>-0.925984</td>\n",
       "      <td>-0.948996</td>\n",
       "      <td>-1.114097</td>\n",
       "      <td>-0.573359</td>\n",
       "      <td>-1.079455</td>\n",
       "      <td>-0.943294</td>\n",
       "      <td>-1.041533</td>\n",
       "      <td>-1.045622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.221742</td>\n",
       "      <td>-1.342884</td>\n",
       "      <td>-1.130380</td>\n",
       "      <td>-1.170083</td>\n",
       "      <td>-0.753493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MT_001    MT_002    MT_003    MT_004    MT_005  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.712761 -0.649143  0.000000 -1.154807  0.000000   \n",
       "2015-01-01 01:00:00 -0.674341 -0.645010 -0.862140 -1.067719 -0.513278   \n",
       "2015-01-01 02:00:00 -0.725568 -0.742124 -0.963111 -1.203794 -0.610849   \n",
       "2015-01-01 03:00:00 -0.727168 -0.826841 -1.022720 -1.296324 -0.666604   \n",
       "2015-01-01 04:00:00 -0.722366 -0.837172 -1.055566 -1.318096 -0.680543   \n",
       "\n",
       "                       MT_006    MT_007    MT_008    MT_009    MT_010  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.500971 -0.765328 -0.665566  0.000000 -0.414196   \n",
       "2015-01-01 01:00:00  0.000000 -0.701394 -0.490022 -0.447094  0.000000   \n",
       "2015-01-01 02:00:00 -0.594173 -0.822705 -0.641794 -0.681695 -0.484698   \n",
       "2015-01-01 03:00:00  0.000000 -0.886640  0.000000  0.000000 -0.602201   \n",
       "2015-01-01 04:00:00 -0.706917 -0.925984 -0.948996 -1.114097 -0.573359   \n",
       "\n",
       "                       MT_011    MT_012    MT_013    MT_014    MT_015  \\\n",
       "time                                                                    \n",
       "2015-01-01 00:00:00 -0.822551 -0.854473  0.000000  0.000000 -0.899862   \n",
       "2015-01-01 01:00:00 -0.770593 -0.822892 -0.849406 -0.507760 -0.835587   \n",
       "2015-01-01 02:00:00 -0.886055  0.000000 -0.951011 -0.735623 -1.053028   \n",
       "2015-01-01 03:00:00 -1.015951 -0.929478 -1.023059  0.000000 -1.177476   \n",
       "2015-01-01 04:00:00 -1.079455 -0.943294 -1.041533 -1.045622  0.000000   \n",
       "\n",
       "                       MT_016    MT_017    MT_018    MT_019    MT_020  \n",
       "time                                                                   \n",
       "2015-01-01 00:00:00 -0.569866 -1.335692 -0.748872 -0.798016 -0.608055  \n",
       "2015-01-01 01:00:00  0.155680 -1.213432  0.000000  0.000000 -0.599583  \n",
       "2015-01-01 02:00:00 -0.145701 -1.310521 -0.952812 -0.716423 -0.691364  \n",
       "2015-01-01 03:00:00 -0.839993  0.000000 -1.093459 -0.977522 -0.729489  \n",
       "2015-01-01 04:00:00 -1.221742 -1.342884 -1.130380 -1.170083 -0.753493  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_missing_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_csv_data:\n",
    "    for i in range(data_train_missing_vals.shape[1]):\n",
    "        data_train_missing_vals.iloc[:,i].to_csv('../../data/traffic_train_missing_40/'+ 'MT_{0:03}'.format(i+1) + '.csv')\n",
    "        data_train.iloc[:,i].to_csv('../../data/traffic_train/'+ 'MT_{0:03}'.format(i+1) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "def evaluate_Testset(y_true, y_pred):\n",
    "    def mape(y_true, y_pred): \n",
    "      return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    MSE = mse(y_true, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAE = mae(y_true, y_pred)\n",
    "    MAPE = mape(y_true, y_pred)\n",
    "    return MSE, RMSE, MAE, MAPE\n",
    "\n",
    "# Function to estimate accuracy for one user\n",
    "def accuracy_Testset(y_true, y_pred):\n",
    "  diff_pred = list()\n",
    "  diff_true = list()\n",
    "  accuracy = 0.\n",
    "  for i in range(len(y_true)-1):\n",
    "      diff_pred.append(y_pred[i+1]-y_pred[i])\n",
    "      diff_true.append(y_true[i+1]-y_true[i])\n",
    "  count = sum(diff_pred[i] * diff_true[i] > 0 for i in range(len(diff_pred)))\n",
    "  accuracy = count/len(diff_pred) * 100\n",
    "  return accuracy\n",
    "\n",
    "# Function to estimate average accuracy for multiple users\n",
    "def average_acc(y_true, y_pred):\n",
    "    n_users = y_true.shape[0]\n",
    "    acc_list = []\n",
    "    for i in range(n_users):\n",
    "        y_true_i = y_true[i]\n",
    "        y_pred_i = y_pred[i]\n",
    "        acc = accuracy_Testset(y_true_i, y_pred_i)\n",
    "        acc_list.append(acc)\n",
    "    acc_np = np.array(acc_list)\n",
    "    # print(acc_np)\n",
    "    avg_acc = np.mean(acc_np)\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Test for 20 users, each user contain a time series data:\n",
    "\n",
    "Setting:\n",
    "- 20 users\n",
    "- each global training round select 10% of users\n",
    "- 20% missing values\n",
    "- each user has a time series data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation score: 0.19399776107933084\n",
      "Forecasting accuracy (RMSE) my: 0.6232490527998037\n",
      "MSE: 0.38843938181585247, RMSE: 0.6232490527998037, MAE: 0.5493146755177989, MAPE: 702.102346787457, Acc: 58.55263157894736\n",
      "imputation score: 0.6703631830199243\n",
      "Forecasting accuracy (RMSE) my: 0.5470237342250083\n",
      "MSE: 0.2992349658054725, RMSE: 0.5470237342250083, MAE: 0.44846569739280495, MAPE: 989.8746832541949, Acc: 72.5877192982456\n",
      "imputation score: 0.7942335479673194\n",
      "Forecasting accuracy (RMSE) my: 0.6472761177671822\n",
      "MSE: 0.41896637263175524, RMSE: 0.6472761177671823, MAE: 0.4986757209176593, MAPE: 1516.1934566145521, Acc: 67.32456140350877\n",
      "imputation score: 0.8640874282447204\n",
      "Forecasting accuracy (RMSE) my: 0.716464458669668\n",
      "MSE: 0.5133213205368204, RMSE: 0.716464458669668, MAE: 0.5520054101007126, MAPE: 3622.6427092310255, Acc: 63.377192982456144\n",
      "imputation score: 0.9808267261948762\n",
      "Forecasting accuracy (RMSE) my: 47.846295662135454\n",
      "MSE: 2289.2680085884817, RMSE: 47.846295662135454, MAE: 11.167299290973812, MAPE: 48066.556229268295, Acc: 51.3157894736842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6232490527998037,\n",
       " 0.5470237342250083,\n",
       " 0.6472761177671822,\n",
       " 0.716464458669668,\n",
       " 47.846295662135454]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sd = []\n",
    "for dim in [1,10,20,30,70]:\n",
    "    Y1, Y_sd, weights_sd, lst_U_sd, rmse, y_true_sd, y_pred_sd = test_sd(data_train_missing_vals, data_test, L=L, n_users=20, M_ts=window, dim=dim, days=1, plot_all=False, plot_single=False)\n",
    "    MSE, RMSE, MAE, MAPE = evaluate_Testset(y_true_sd, y_pred_sd)\n",
    "    acc = average_acc(y_true_sd, y_pred_sd)\n",
    "    print(f\"MSE: {MSE}, RMSE: {RMSE}, MAE: {MAE}, MAPE: {MAPE}, Acc: {acc}\")\n",
    "    rmse_sd.append(rmse)\n",
    "rmse_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting accuracy (RMSE): 0.5869669019545368\n",
      "MSE: 0.34453014399010684, RMSE: 0.5869669019545368, MAE: 0.5244784288401328, MAPE: 779.3302219115574, Acc: 62.280701754385966\n",
      "Forecasting accuracy (RMSE): 0.5245326716796014\n",
      "MSE: 0.27513452365934044, RMSE: 0.5245326716796013, MAE: 0.43364884288400807, MAPE: 277.76498324529314, Acc: 68.85964912280701\n",
      "Forecasting accuracy (RMSE): 0.48209830846604523\n",
      "MSE: 0.2324187790258221, RMSE: 0.48209830846604523, MAE: 0.35976146673535897, MAPE: 1173.0700890585408, Acc: 63.377192982456144\n",
      "Forecasting accuracy (RMSE): 0.7056659188459354\n",
      "MSE: 0.4979643890206784, RMSE: 0.7056659188459354, MAE: 0.5547211947228863, MAPE: 1069.1196923456055, Acc: 58.55263157894736\n",
      "Forecasting accuracy (RMSE): 2.136107682809416\n",
      "MSE: 4.562956032557414, RMSE: 2.1361076828094165, MAE: 1.6400777262671415, MAPE: 2595.8455279974655, Acc: 53.28947368421052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5869669019545368,\n",
       " 0.5245326716796014,\n",
       " 0.48209830846604523,\n",
       " 0.7056659188459354,\n",
       " 2.136107682809416]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_mssa = []\n",
    "for rank in [1,10,20,30,70]:\n",
    "    Y2, Y_mssa, weights_mssa, rmse, y_true_mssa, y_pred_mssa = test_mssa(data_train_missing_vals, data_test, rank=rank, L=L, n_users=20, days=1, plot_all=False, plot_single=False)\n",
    "    MSE, RMSE, MAE, MAPE = evaluate_Testset(y_true_mssa, y_pred_mssa)\n",
    "    acc = average_acc(y_true_mssa, y_pred_mssa)\n",
    "    print(f\"MSE: {MSE}, RMSE: {RMSE}, MAE: {MAE}, MAPE: {MAPE}, Acc: {acc}\")\n",
    "    rmse_mssa.append(rmse)\n",
    "rmse_mssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation score 0.06632447452234486\n",
      "Forecasting accuracy (RMSE) my: 0.6011275011908324\n",
      "imputation score 0.316703310537115\n",
      "Forecasting accuracy (RMSE) my: 0.7734631200156228\n",
      "imputation score 0.44672998486748455\n",
      "Forecasting accuracy (RMSE) my: 0.6071694577009967\n",
      "imputation score 0.5461435213985157\n",
      "Forecasting accuracy (RMSE) my: 0.5528768773287615\n",
      "imputation score 0.8431659863644058\n",
      "Forecasting accuracy (RMSE) my: 0.5042878968986745\n",
      "imputation score 0.9021639806057836\n",
      "Forecasting accuracy (RMSE) my: 0.5028041497070108\n",
      "imputation score 0.9553705948854567\n",
      "Forecasting accuracy (RMSE) my: 0.5041238021521246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6011275011908324,\n",
       " 0.7734631200156228,\n",
       " 0.6071694577009967,\n",
       " 0.5528768773287615,\n",
       " 0.5042878968986745,\n",
       " 0.5028041497070108,\n",
       " 0.5041238021521246]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_fedmssa = []\n",
    "for dim in [1,10,20,30,70, 80, 90]:\n",
    "    Y3, Y_my, weights_my, lst_U_my, rmse, imputed_data = test_fedMssa(data_train_missing_vals, data_test, L=L, n_users=20, M_ts=window, dim=dim, days=1, plot_all=False, plot_single=False, missingVal=1)\n",
    "    rmse_fedmssa.append(rmse)\n",
    "rmse_fedmssa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get imputed data from FedMSSA and Store as file for FedLSTM\n",
    "\n",
    "## Best rank for Electricity Dataset:\n",
    "- Missing percentage:  0% - rank: 80\n",
    "- Missing percentage: 20% - rank: 70\n",
    "- Missing percentage: 40% - rank: 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation score 0.9021639806057836\n",
      "Forecasting accuracy (RMSE) my: 0.5028041497070108\n"
     ]
    }
   ],
   "source": [
    "# Get imputed data from the FedMSSA with the best rank (=30 for example)\n",
    "MISS_VAL = 1 # Working with missing vals or not\n",
    "Y3, Y_my, weights_my, lst_U_my, rmse, imputed_data = test_fedMssa(data_train_missing_vals, data_test, L=L, n_users=20, M_ts=window, dim=80, days=1, plot_all=False, plot_single=False, missingVal=MISS_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100, 173)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert imputed data to an array\n",
    "imputed_data_np = np.array(imputed_data)\n",
    "imputed_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 17300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten page matrix\n",
    "imputed_data_flatten = []\n",
    "for user in imputed_data_np:\n",
    "  user_data = user.flatten('F')\n",
    "  imputed_data_flatten.append(user_data)\n",
    "imputed_data_flatten_np = np.array(imputed_data_flatten)\n",
    "imputed_data_flatten_np.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make comparison between imputed data and original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 17376)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the original data train\n",
    "ts_data_train = data_train.T\n",
    "ts_data_train = ts_data_train.to_numpy()\n",
    "ts_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17376,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 1\n",
    "# Get actual data for a user to test\n",
    "actual_data_client = ts_data_train[user_id]\n",
    "actual_data_client = actual_data_client[-25920:]\n",
    "actual_data_client.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17300,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get imputed data for corresponding user\n",
    "imputed_data_client = imputed_data_flatten_np[user_id]\n",
    "imputed_data_client.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwy0lEQVR4nO2deXwV1fn/P4ddBFQgKgU1iAugiCIqrlWxfnHFrdXWvYo/rba13/ryi1vV1g3XaqsiCioudUessiPIFpCEfQkQSEISQshC9j33/P64c5O5lzt3tnNmztz7vPvy1ctk5swzM+d8zv48jHMOgiAIIhh08tsAgiAIwjok2gRBEAGCRJsgCCJAkGgTBEEECBJtgiCIANFFRqL9+/fn6enpMpImCIJISrKysso452lm50kR7fT0dGRmZspImiAIIilhjOVbOY+GRwiCIAIEiTZBEESAINEmCIIIEFLGtAkiHi0tLSgsLERjY6PfpvhGjx49MGjQIHTt2tVvU4iAQqJNeEZhYSF69+6N9PR0MMb8NsdzOOcoLy9HYWEhBg8e7Lc5RECh4RHCMxobG9GvX7+UFGwAYIyhX79+Kd3TINxDok14SqoKdoRUf37CPSTaBEEEmr1VjViwpcRvMzyDRJsg4rB48WKsWLHCVRq9evUSZA2RiOvfXoG7p6fOZj4SbYKIgwjRJryhqLLBbxM8hUSbSCmuueYanH766TjppJMwZcoUAMCcOXMwatQojBw5EmPHjkVeXh4mT56M1157DaeeeiqWLl2KO+64A1999VV7OpFWdG1tLcaOHYtRo0ZhxIgRmDlzpi/PRaQOtOSP8IWn/7sZW/ZUC01z+C/64MmrTkp4zrRp09C3b180NDTgjDPOwPjx4zFhwgQsWbIEgwcPRkVFBfr27Yt7770XvXr1wkMPPQQAmDp1atz0evTogRkzZqBPnz4oKyvDmDFjcPXVV9OEIyENS6LNGPsLgLsBcAAbAdzJOQ/cuqW6plZ06czQvUtnv00hfOKNN97AjBkzAAAFBQWYMmUKLrjggvZ103379rWVHuccjz76KJYsWYJOnTqhqKgIJSUlOPLII4XbThCABdFmjA0E8CcAwznnDYyxLwDcBOADybYJ56Qn5+LYtIPx418v9NuUlMesRSyDxYsXY8GCBcjIyEDPnj1x4YUX4tRTT0V2drbptV26dEEoFAIAhEIhNDc3AwA++eQTlJaWIisrC127dkV6ejqtwyakYnVMuwuAgxhjXQD0BLBHnkly2VVa57cJhE9UVVXhsMMOQ8+ePZGdnY2VK1eisbERS5YsQW5uLgCgoqICANC7d2/U1NS0X5ueno6srCwAwHfffYeWlpb2NA8//HB07doVixYtQn6+Je+aBOEYU9HmnBcBeBnAbgDFAKo45/NkG0YQohk3bhxaW1sxbNgwTJw4EWPGjEFaWhqmTJmC6667DiNHjsSNN94IALjqqqswY8aM9onICRMm4KeffsLIkSORkZGBgw8+GABw8803IzMzEyNGjMD06dMxdOhQPx+RSAGsDI8cBmA8gMEAKgF8yRi7hXP+ccx59wC4BwCOPvpo8ZYShEu6d++O2bNnx/3bZZddFvXvE044ARs2bIg6tnLlyvbfkyZNAgD0798fGRkZcdOsra11Yy5BxMXK8MglAHI556Wc8xYA3wA4J/YkzvkUzvlozvnotDTTiDkEQRCEA6yI9m4AYxhjPVl4HdNYAFvlmkUQBEHEw8qY9ioAXwFYg/Byv04Apki2i0hSOOd+m+Arqf78hHssrdPmnD8J4EnJthBJTo8ePVBeXp6y7lkj/rR79OjhtylEgKEdkYRnDBo0CIWFhSgtLfXbFN+IRK4hCKeQaBOe0bVrV4rYQhAuIYdRggiFOEIhGq8kCEIuJNqCGPn3eTj7hYWu0liUvQ9/+XydGIMIgkhKSLQFUdPYipLqJldp3PnBasxYWyTIIoIgkhESbYIgiAChvGjP2liM2RuL/TaDIAhCCZRfPfKHT9YAAPJeuMJnSwiCIPxH+ZY2EWxGPj0Pr83f7rcZBJE0kGgTUqlqaMHrC3f4bQZBJA0k2oRSZOXvx4gn52J/XbPfphCEkpBoE0rx1qIc1DS1Iit/v9+mEISSkGgrSmNLG+2wJAjiAEi0FWXoE3Mw8ZsN5if6yNnPL8T4N5e7TqeuqRVVDS0CLCKI5IdEW2G+yCz024SEFFc1Yn1Bpet0znpuIUY+TWFHCcIKJNqE79Q2tfptAkEEBhJtgiCIAEGiTQjh01W7sXjbPr/NCAyNLW34eGU+hR8jbKP8NnYiGDw6YyMAcjdglZfnbsN7y3LR7+BuuGzEAL/NIQIEtbQJwgcq6sObh+qa23y2JHlIlV4LiTahJKlR/AjCPiTahFJEgrRzzjF7YzFa20L+GkQQikGiTSjJ7E17cd8na/DOkl1+m0IQSkGireNP/1mL95aSSPhJZFiyrDYcum1vVaOP1hCqUd/cirYUd+9Aoq3ju/V78MwPW/02QyjpE3/AfR9n+W2GbVhknIQgdAz/29yUD35Nop0CzN60128TiFhSu7Hoiu/W7/HbBF8h0SZ8obUthI9W5qf8RCP1Jwi7JN3mmv/8vBtnH9sP6f0P9tsUIgHTM/Lx9++3pLxoE4RdkqqlzTnHI99sxDVvuXcXSsilUnPFmuouWd/+aaffJhABI6lEO0JlfWoLgRHpE3/Ac7PcTbQ2trTho4w8KQEa3li4Awuzw/5LUmV3W86+Wr9NkMYXqwtQUFHv2f1SJMsEX7Q552hsoa3AVpnict3zK/O24YmZm11Nbra0hfBGnGC/r1LU9kBy4zsZmDQnO+pYc2sID3+9Ab+enOGTVclL4EX70593Y+gTczyt0VOZ/Vovpq7ZuQ/s3Ta+Fa3884apy3Kxo6TG0bWrcivw9uLoYR6uLY+poADNwgm8aM/eGG7x5ZXX+WwJQVhHtZ78P77fgqv/LX8uqK6pFcc+8gPmbqZlqE4JvGgbkay7pspqm1BU2eC3GZ4xPSOfWmse0eDBMGN+eT1CHHjN4lBYKMSxqagKgLh5jtqmVrw6bxtaArpyyZJoM8YOZYx9xRjLZoxtZYydLdswt1jNFEFj9DMLcO4LP/pthjCslMPcMupFJWLZjjJsLa722wwpvLdsF6781zKs2lWOIY/OEpLmq/O2440fczBjbZGQ9LzG6jrt1wHM4ZzfwBjrBqCnRJuEsFGrnQki2bll6ioAyRmA4rlZ4QnOosoGiOo8R3oUQW1pm4o2Y+wQABcAuAMAOOfNAJTsr6bKkp9UgHyPEER8rAyPDAZQCuB9xthaxth7jLEDthsyxu5hjGUyxjJLS0uFG0oQRPDgDqdcC/fTajAjrIh2FwCjALzNOT8NQB2AibEncc6ncM5Hc85Hp6WlCTbTnFRsZeeW1UnZ5OKWrPz9CSdLVf5Wu8vrUVyl/kTv56t344vMAr/NMIS58Kry3fo9OG/SIizPKRNoUfJgRbQLARRyzldp//4KYRFXglTqRZdUd/iW3l5Sg4teXow3F+VYutbL1TTXv70C501yN1nq147IC15ahLOfV3+i9/++3oiHv9ogJC0v37WVlve63ZUAkLSTq24xFW3O+V4ABYyxE7VDYwFskWqVRlZ+hRe3cURzawj7PV6Kpg8IEGnJZubvjzqnurEFD3+1HrVN0ZtfXpm3TawxJmVP5dZ0hJnrinDco7PQ1Eo7ar1GxpxFALKcEKyu0/4jgE8YYxsAnArgOWkW6SiocN5Nld0C//Nna3HaP+bLvYkDpvy0C19kFuKD5blRxzN2lftkUWL8LGgvzM5Ga4ijvFbJeXXfKK5qSOh9cV9NIy5+ZXGAdyHHz3VB2dthSbQ55+u08epTOOfXcM73m1+V3KgaWMDpxI9tPByWCsIQWFVDC9In/oDpGXkAgD2VDYEUtYq6Zpz9/I8JIzjNXLsHu0rr8OGKPM/skpEH9OPuy3PKMOTRWVi7W31pU3JH5K1TV+GKN5b6bQZBWCYy3/BRRj4A4JwXfsT5Ly7y0yRHRFzlLt62z1U6shsPuWV1mDQn29V4vN7Gn7aHV7z9nKvukGwEJYMgLN3hbNY4GJ2bYNDY0oam1hAOOairsDRzy+ow4JAewtLzi3eX7MKZg/ti5FGHenrf5tYQunZmtIYdwO8/WI3csjpcMWKAg6uD/f6UbGkTFpBcQ13++lKMfHqesPRa2kK46OXFeODTNYEY7kjEs7O2Yvyb3gbaKNxfjxMen43PV6u7zE+P0ZI/URPU1VqP4K4PV4tJUCMI8SeTRrRTtZUtSwB3Cfb3EZnkWbqjzHbBDcJKFLvY7dbvLA1/jx82FsswJ3C0avmppLpJaLqb96i/zDBpRDuWgDfmXJO915lvZNk0tarn7yEJ6wRbeFkpyuxlOQldtyh7H9In/uD58l03KC3asZMZ//5xB77OKvTJmmAQKYDfb6AWmRmpXrE7xbMVSja5/5M1ts7fV92E//1iHQB1GznxUHIi0oiX54XdrV5/+iCfLSGEkSRjH0nyGO1YeRxZrWbH/koqrS6xDKf/epyQd0FA6ZY2YR/PJvmSpEstmiDZGg+VzKe5j/iQaCuIlUkqv7qoKhVqt8h4g6kiHFaJfR923s+iBGvFZfpLKa8VO7kpmqQRbQb/nAz5idciGnnDpaIytgJNUxEWKPAYSmH2Pqy8Lr+CFMT67VGNpBHtWLmO3YAwbVkukhHZ1ZSRP4aX5gp2QJVE1DSar2JQtXmhkl0p2AazhNKi7cYnbyx//94Tx4SeIfLdJOJ8ly5W42O/NBZU1EvrtorWhiCs9TUi0ltNlLtki6n8vH1g+qquiImH0qJN2EdfoER0L/fo3MEaYdcxUl2TfVeo57+4CGc8u8D2dYmwIw0l1Y1YlO3OH4cbZMqYXq6mad4hra0e8W9MKN69U2WISmnRNqr9cvbVemxJMKnwaMPA12vsrZ2P2gJuo9nmp+fM699egTs/ELtl2g5ePfqGQusBsVNxDkkFlBZtI1pD6u2qU5Fpy4M7jq/XAxUaUIX7E/t2TyX9stKiFfE+9Em4HTIJhbhufibYHyuQok1YG4PLylPfN3CyoUoX/Znvt+DlJJ4strtlffybyzHk0VmWzlW9AibRDhDxBCH2kCqikQxwzvHS3GxsL7G3xVlf6IurGpA+8QdsKrI+7CCC95bl4t8W44f6gZf5tKq+BRtN3r9XE/siSBrR5lyd+d/MvAp3ztkNLlW9BeAEK4/U0CI3hqPRt6puaMWbi3bixncybKQV/e/F28LO9T9emZ/wPNk0t4YQEjQpIGToI0EaTkuyUZq/fmeFo/RUJfCi7WQGe8XOMqRP/AFlEpaQzdlUjBsmZ+AzBfwey9CFeG/bTSFenhM/4IX+s/7u3VXObyAAK7EDVe/hnPD4bDw6Y6PQNBljwiqCuOkLSmd7ib2FC6p/y0CKttuafurS8ATdut2V7o2JIb88vPwtV7A/aqv43Rq36+KyscX/SWU/lq75IQxWGhIRs6zmo0hMTNnI7ker0083JzCivb6g0m8TAoeMJVlmKVY68GlM+IubfJJXHrzgxUEnMKJdXud8KGNPZfRyLSfO0r3EShFyo8e5ZXV4a7Eak1RGj2H0fI2Sx7ed4rZ+zNlXg/8mCHUlumG+clc5Tnx8Nirro3tGqrY3gzRRKBulRdtNQdB/4ljRzsxXaync9xv2YF+N+c7DeDjp2v/u3ZV4cc42T6N1iBoO8GrDkFW27KlGfXOHgyGnz3nJq0vwx/+sFWSVOW8uykFTawjrDTbTiB6+eXX+dtw0pWNCV/VxY5UJTBCEbXs7JhOS6YPXNLbggU/XYuiRvduPNbVGtyY3FVXhyn8tw8TLhrYfiwwXOenail6NIcOZfBC+cWNLGy5/YykuPDENj1w2TOq9VGoB27Elcu4bigcc0Bcjv+eFzFC6pa0vuJPmZAtP3+jbNDS7FzWrYhrZ3KnvDTzyTfQsf8bOcgDAj1s7fF9k7Y7fW9C/M8XzHgDjbr+XBcfsWxn9tVnz7WJlE5Mbv9KqEu/bNba0WVptQzhHadE2gvPwKgX9+CaHuIJgZ9z0p+2lUf+OiOa7S3PxwKdr8JvJ4S5hS1vIsgOn+VtK4v8hAK3PIGE2tNTswOFW0MXY7uqRWIY+MQf3fpwlzB47BKF3JoJAijYAnPaP+bjurRW+69jt0342/Nv3G4rxc14FAGDk0/Mse6mrF9DSB6I13rMoZAalPYhi9sg3GwBY+x6mTv/9zqgGHPC9bBhaUh09D1OnBQ8wbHTYxMsso+r3iUdgRRsAthQHx29xfXMbKutdrlqxMO5meNziMTMytUpIFHa/oZcFOdKLEtHdX7oj/iYivxCxNv3bddGrXZ78bnP7b6N1z1YqbxErRarqW7ByV7mja1UX8ECLNtBRiFvbonOD1Rf//Oyt+Ozn3e5s8KgZqS8IkVtaLXz69+MmT5qty/XTx7JdRH63qImsOIJVVJnYS6CfRFnr4p2U1hy4LNcoN1jzFKjLszY9C946bRVumrKyfT7IjCAtKQy8aEeYMD3T9jWcc7zz0y5M/Mbd9t4MhzW6VQKkg4ao/AwiKxqVnxMIzwUtU6zVH4uI3YkRv+APfLrmwPTjJG/lnq1tIeSX+7PTWY/Sou2n46TnZ21F+sQfLJ1b26hbp+uwxjZ6pDoXQUYDOIzsC3Za3PHO9eI9i6oLbpv2M26ZugrN2rJS2ba7Sd9uZepGF6ws+XtuVjZ++dJiFFf522tSWrStYDfUlR6jiOKMAe8s2eUoTdE+DP4hIbZlIgvLapvidnOTETNRkNlltptLnv1hKwD3Y+MRN7N+Twx7df/yOJuxnPaGVuwMv/v9df7uqA7M5hojrDhmMsofj83YJNYYFxjlo2oLkb1FMvoZsXEYA43Fwu3FiMg2mz69HSN5fMco+X01jbhpykpMvf0M4WnHYtfrn2oEUrSNPo6oVq7frRArGD1r1OYag+eQGiTW4KZr8isl3jV1iV3739DchoO6dfbJGnPiZY+q+hac+exCAMB7S3ehW5fwAAAzuS5++hzfritKeE6WYm4s7GJ5eIQx1pkxtpYx9r1Mg8TB4vySg2yND8UbR42sHjE4HotZ5A7Z/HPBds/uxTnH9Iw8T32rdNzb2/vN2ljc/nvmuiIM+9sc25F24rHbxbCjFfSNi9JaZ3534rE8pxx/+Xy9sPRUxM6Y9p8BbJVlCBEfzsMTIF4w8esNntxHNpv3VONvMzfjf79Y57cp0tGvIV+guTnYmmDte+TsdtHkiSuamsaWA3pPXlVMesduVoc+ahwOJyZKv6qhBTt0FaHfK4QsiTZjbBCAKwC8J9cca9jNNCIj1OSW1WGtgd8PwHzyqrk1pHlYc7frUUbGERFtR/Y67VfnmbfYm1rDQwYyfHub5T2zx69pbFHWvSyAqAcsqKjHiKfm4f3lef7Z4xGJvutvJmfgV68t8c4YE6y2tP8J4GEAhs4YGGP3MMYyGWOZpaWlRqeZkqebWBRV/u/9+MC1mrEs3dFhc6L7XvTyYlz7lvOYcx+tzMdLc7fhPS16TgSnPrTdNHqsLnV7c1EOntLtdnN0L1dXd/D1mkJBKXXgtuVo5/IRT83DRS8vdndDE56P6ZnpK4kDfIskyOuRIZIFW51vS/dq45lbEvVOPJsEtoipaDPGrgSwj3Oe0AsM53wK53w053x0WlqaY4PWF1bq0nScjG2+yhIvBvFo0Hwvt/tgNqmYymvjj8u6WY4WaQ1b3Z790txt+GBFnu37bNT7arb5LYMQ/ineF7CyMqG4qlGYmMVLZm+MT5DHv1VnlVR8b526+ScXDTU311opCqrUP1Za2ucCuJoxlgfgMwAXM8Y+lmoV0U59S/zNNW5ELbJh54mZcgvz0/911zp3i9VCZlTYzTRARhmubmxJOPyWCKOITJsSTULHPoTk4a1lBoGcRcC5N+PNyo9pc84f4ZwP4pynA7gJwI+c81ukW+YSv1+sZUxKvptdoUanRMZ85wnyxhZ1T0HNkeU5zl0DiPr2VtM54DQrTpEMEp/wYSaufWuFo3HvJdutD0s6rai8QJUWrRF+r/MO/I5IPSpEn3AqGE4LS8LrFMr9QRjuUIGIz4x4yzxFYCdVo5a7lW9pOmGrRPVgj0Zt8cCfPAwLFw9bm2s454sBLJZiiUaQvMQ5YfJP9rbHq/Q6svcGxxWuLFSoeu7+0L5zNCe8Nt/92nor5Vl/CgNznOdlt1FkVaR2SaqWtgqYfddabTzZakvDVYvEJPdHbK2OsxY3HuP+udS5LUmM10XZzWqOAzZjaf/r+HcHEZGKzUYvztnm+P4y4ZxbWikWdEi0A4ooodhX04hTnpqHNxflCElPpZ6S1Xe0vqAKI56ae0Ckd7N67IMAr1+20xhw5z1PjdZpMqGcaFvJSrLHR+2G+3KSL2OfwSgJ2c9aUhXeeDRn817haest97Ls2q023v4pBzWNrVhl0y96sq9fllkBJ8rXKm3m0TukK6hQI5CFcqJthSdnmi8lc5PfznnhR+cX28WpneqX+cCjUKfBFdFRdRKzc1/HygivHj8qlqnkm1bW2/NH89CX8f2YNLa04ZcvLbK1YkcUSou2UWMkU4KXLjcNH/26Wq8LesL7+dCaC0IL0ipmQwgyH1X2azTKN7W6oBsyTdC/W1H3sZLOev2GLxcU7q9Hfnm9L3sRlBZtL9HvxLSLk4AJ7ZnWRo61tNXdtiXadZJFIghSbs2VwIFniayn7Vb6bt+rpUC7SdLjSBaUE22/Mojfy3mMHjt67bl4G6/69zIAYc94IthV6n8MPbsYtagbTDa4WJlvUEHv9L4zVLCHcIdyoq2HanhzIu44I7y9eKdPloS5WxdgWfZQycKtJVhXUCn1HomIiD2HsYD73cNwE2PUlzFtyfeymyf9cGVgRiAj16QShhUXVWi4S9tkkvfCFb7cPwiNijUxfkwiIuPV7mG/K61kROmWtpf4va3WKHMb2uXC94gfJNMEpRky5x5EYafCSaFPB8Det/FDNZQTbVHiKepl5pbV4e//3YKQRTemVmkvNDYMtbtu1jBGZABaiHaoNRoCcKE2K2x6oxNd6cvWSSt5QGY+kZG2lc+9M4BzLrEoJ9puaI4Jcrooe5/raOb3TM/EtOW52Fkq1rPXFosTf/qxUn0QVzebbpJMsw94lyI2hSzfGV+0/dowJBo7tsuu5K18r59zK0zPsVImFmXvMz1Hj5lpfmQBpUXbbqF49vuOEJbFVY2484PVePCzdZauNfo4EaF8YbbYOI0LbWYeoMMDnFsCrDVKEREJGZomKs3YHoBM/Y1XhkTdb8VO892qoipRq16B/EI50XZTq68t6Jh0iSzX0ocvc0JLWzgnOBHZjjQMo7SZKqjfY+1u4Aa/ZbO3yn10b28FQB5W3CVYjWBkei+fWwMybm/8TP49rHKi7QZ3jm3E2RHLjLVFpucYrtM2yByV9ebDPio7uhdJ7HPe+3E4Mp7dT2o3D1hZ8icbtxO8nAPP/LDV/ESfUTXP0kSkQNoDmLpNR8BXcdOS2VQUf+x7xz7zMXZVM7oquP22Vq5XdShKb7s+qLUfRPsekZtr7VauNKbtIXa/vd8rKtx8/KLKBox+ZgHyy6OHgozSFLwQxhJ+d53jkcgm6eZ69D6sDK+ZhbRzM0Rn6L3Sp/zgJkxfNDSmnboI+Pbfri1CWW0TPltdEHVcRaFUEadrloO8KcXvvKF/516a4nfjTARJJdqRGG5OkPkt/S4ghDXcLaNUa39BBLNnSvTXiMDJGK+XUSa8LWc0ESkEGU7KZdbMxVVi7VWtcrDjxzmZ+NHKSiOPWnz/Whg/IpGlzTU2jfQ6qLUTnE42q4Ryoq3aKxLx0Sob4jter2l07sxHTyC6fIrVKM2tIRRVRleaTr917FVWN055wc955ptSjIi0sIstLqG084k5OOZt3ovHv93oxDQFoDFt3xElKXnlB64Ln71RfCivePi17MxvnBSftxZ3tEDtiM37y3MPOBa75E//Oxj1aeIXsKu0Dlk2A4/M21KipW18zj0fZeHjlbttpesFqn+zpPXyF2k11bjcxm6XeJnQ0G1nuLS7xqiF6LeI++k21Yx469ytvK8vMgtMz1GsU+EYfb7K2VeD6sYW9OjS2dK1z3y/xfp9hKmkBf/mqiuyBZJWtCOU1VqLCWf0LZtbE+xmVJxkEQ+nWH3+eAXZcBmcc3NQUFFvO6GZ64pw4YmHG/7dqT128wbnwJ3vr3Z4t8Qk3DEcwcqaeCvL+QLmHTMeyom2XzWh0aL+vdXut0QnvrHAtFTPbZJQufWk/yRzNlkfJuOcI2dfDf782TpcMuwI8Ybp72V43DxD7dZXRA655NUl7b/dfEtLLnGToIzQmLYHyB6+UFm0vIDzcJTtRpPwYGJuZn6K0fd4dpa97eINzeEW6N5qcauM4vUc3QiZUU/ULMlkEE+/INFOImLLQZCHduxy6t/n45o3lzu6tt3lgd3lYEbxKUTMU+gS9ysyu6XdlPpJV4mNByuxR1Ml0AaJtgfInhA0KitW/JMkAxGxyN5bk/hEITfr+KnXCBnreb3oQXHOhQXLsONjxy99tf1OFQwSqaBo61oYblJRaMjAMNp3swfdeUXwo4wmqiwdb6OO2jAk76la20JShc2SsysLm6P0ebupJaQ77tAuF5WfFWdTydAYV1C0U4e7P8w0P4mQQrzCGy3kBss09edHNTDin79ql7nzfj312rj8Y99usnWdXWSLly+VtB+K7EPjkERbQ6rvEYMsXF7XnLIrPsQi5uuJGtPW8+26PfHvlWjtPoD5W0o86y0a2WL3/nZ6Hipne7uv/bhHZwmPbJUI5URbpWGNoKHyRIxXplndTKXPZ0pmOcnva19Nk9TbmA4FS8gQlpb8WTgrujdlfnJriGPyTzst3F0Myom2HiULkwMSjtMJeMggVHRe7c70ctWFTKy+r5fmbnOUfo5uklpcaDX3GTEIeRnw105T0WaMHcUYW8QY28IY28wY+7MXhhH2seRdLsnxZK22CV7WFaVai1kG1nYPin1a1Spa1YI4ANZ2RLYC+CvnfA1jrDeALMbYfM65decCPmA7bJHEmtOrVuZOC2tZk52Hv9rQ/tv+mGxqIuq5/fZ144uQqjgRyTkv5pyv0X7XANgKYKAsg3zrdQS4xKro8zcWmQXq45X57b+trtZ4f3le4hOMfI/oHkTmM7X6ERMuhqjVNAbm6DdwqdZKFoGVMW2vsTWmzRhLB3AagFVx/nYPYyyTMZZZWupvoFDVSCSqJbJ9m6QA+mj3ssuQpfQFGOGVACa6T72FfQSr8+y5bDVD9lixsPF7lce0IzDGegH4GsCDnPMDvLxzzqdwzkdzzkenpaUJMc7V5hrpF4jhd++G6z8rBcSIoEzeeI0M4YuOHN7xW9/at4KtgAE+tWBFOIPyEpVXT4nEkmgzxroiLNifcM6/kWuSGPZJnKARSVlt2M5QimQ4ldELsrHnO91v3T9UdOZvBVkVvh8Oo6wkGSlvru/lY3G1snqEAZgKYCvn/FX5JolB1Mchgs2/Fu5A9l5r4b+ElcOA9Xz8GDKQMmlpIUm7k/Uq9mKttLTPBXArgIsZY+u0/y6XbJfnKPhtCAfoBai1jeOV+dtx7ZsrEl9ko2TGE7japphYnwHqNIWfx8qGEwvnRDnQsn6unqCUQz/F3HTJH+d8GYLzLpVkY1GV3yakNM1mkVEcNjXdFFwVW3CBJ0XeqXI7IvXrq6savI3v6CfJPqTtx/NtK/HAVatDVFmmef+na/w2IYr3luU6vzjJy1AE5URbzwItojMRfLwqT07GStcXhntCdlcfJENF2xYy9qdtl0xdxPYkeDUA1Klc9Sgt2gQhAidLwaxc42YyrVQ3UR6EpWqiTZTxxHLSVO/bKC3aqr2wAkXXrdresk84Jiq8lovYn1aEui52gjNAyPSJYoSoyk/1SlQ50fZLfqwI33Vvm6xCIAxRqSDsLpdb+Vp51KgACgbn3/nB6vDfRRjlEtHtApXyQ9BQTrT1qPZdy2ntt/LEyzOxh/ZUiYtuLhM3u2TtYMkPdQCGR2RgNqbtx3MoLdqENWhwxDui4ybGL7L6CTkjfs6rEGUSIRgrvrpufGelfEMMUE60aXiWkI2bLKYX7U1F1nZamqYpJBVC1Ht8wkJ8zsiOaz/kSjnR1qNaZlZ1wk9Rs3zBlZOxJIl6YxcaX44mQ+feN8NmYGYvUFq0vYR0Ty5+6oLVe/slXn6LprXYimLZlSQBO2hMW3HaFHBMTxBEaqOcaEd19T3UyB26QKdEcNFHUrGLX+vw/W4KyG7oU6APsSgn2npU21xDOEelb2k0N/HyvO3tv9WxVv7wSYuZQy2XPDdrq9T0/YQmIglHrFRwsiQWkc6/DnCFKoHpGXlxj8sQUK/WY/t1/5nr9khNP4LIT7NsR5ml8/wIXqKcaOsXs4uOP5es7K9X3xtiSbW4jUknPzkXK3ZaK1ROaWmLXxj3VInv6j/05fqEf8/eq4C3wgCsMGloEVf53DJ1FTJ2mjeG/AjJppxoE/ZJxTHDSGzNZMBqZB3CW0ot7ID2Y20CiXYSkC/ZlwYhl4IK9bfVp+LKqZfnbrN1/vqCSjmGxECiTRCEKa/oJmlTBbtDH//39QZJlkRDok0QhCk1AXYT6xVezT2QaBMpB237J4IMiTZBEESAINEmCIIIEOqJNnVdCQms0m1AoixGBBn1RJsgJPChwQ5HgggaJNpEShAKAfXNrb67QSUIt3Tx24BYqOtKyKCivhnD/zYXAPDY5cN8toYgnEMtbSIlKKvp2JL8/QZvHBgRhAxItImUQL82OwV3ZBNJBIk2kRJ00ql2KvrRIJIH5URb1eC5RLDRi7YfPpAJQhTKiTZByCB6eIREm5BDo0Cf3kaQaBMpgV6naXSEkMWMtUXS70GiTaQELaGOOIghUm1CEiLD6hmhnGjTiDYhg1Zd+LBdZXU+WkIkM62SgyQDFkWbMTaOMbaNMZbDGJsoy5hQiGNrMYVeIsQjO+I4QQDeDL2ZijZjrDOANwFcBmA4gN8yxobLMGba8lw8PztbRtJEilMsISAvQcTixSS3lZb2mQByOOe7OOfNAD4DMF6GMdtUiDpNEAThEC/mS6yI9kAABbp/F2rHomCM3cMYy2SMZZaWljoy5qBunR1dRxAEoQJtirS0LcE5n8I5H805H52WlubMGNpYQxBEgMnK3y/9HlZEuwjAUbp/D9KOiTeGRJsgiACzcleF9HtYEe3VAI5njA1mjHUDcBOA72QY82N2iYxkCYIgkgZTf9qc81bG2AMA5gLoDGAa53yzDGPyyutlJEsQBJE0WAqCwDmfBWCWZFsIgiAIE5TbEUkQBEEYQ6JNEAQRIEi0CYIgAgSJNkEQRIAg0SYIgggQJNoEQRABgkSbIAgiQCgj2l44DycIggg6yog2RWEnCIIwRxnR7tyJRJsgCMIMZUSbIAiCMIdEmyAIQhDXnXZAfBjhpLRoXzr8iPbf5x7Xr/33g5ccn/C6S4YdEff4FacMaP994+gOF+TH9j847vl/u3I40vv1BACcPLBP+/GunTuGiibfMgrnDOmHXw0/AvddOATDB/TBrWOOwXPXjsADFx2Hu84bjEN7dsVBXTu3pwmEM8/JA/uge5dO+N1ZR+Otm0ehW+dOuOCEcICKXt274LlrR+DkgX1w+YgjMfGyoejTI+w/7MpTBuC3Z4btP2twXww4pMcBzzQkreOZfn36oPbfkecBgGEDOp5p5KBD2n/feW56++9HLx8a991EGHfSke2/BxzSA8f064lLhh2BKbeenvA6ALjjnHRMun4E/vqrE9qPDTz0INPrEvHARce1/+7R1V7xuWLEgAOOHdX3IPxS+yb9e3WL+luv7h3+3I7sE/4Gab27tx87eWAfdOsctuG6UQPbv5/+XUe+IwB8+Psz8dClJ2DcSUfixRtOQa/uXTDgkB5Rz/SXS8Lv6oz0w/DajSMBAMf064n7LhyCBy85Hp9OOAuv33Qqxg49HJ/dMwb/GH8Szj++P6bePhpf3ns2rjhlAO67cAgeuOg4/PbMo/HebaPxx4uPQ/9e3fGfCWPa7zPl1tPx8LgTAQA3n3U0Rh51KABgwvmD28/Rf/tv7z8Xw7X89NClHd9Tz21nH9P+e7gu7x2ue2dGnHhE7/bfZx/bDzecPgh/GhtfB3p264yTfhFO//07zmjP89edNhCv3niq6b3cwriE8DijR4/mmZmZtq8b+8pi7Cytizr27m2jMWF6OK28F65Ac2sIJzw+GwCw8alL0btH16jzm1rb0NQaQp+Y4wDwUUYenpi5Gf/vgmPxyOXDDO2I3OOQg7pi/ZOX2n4OIj5//WI9vl5TiLduHoXLYwQsY2c5fvvuSpx3XH98fPdZntrV2hZCJ8bQKcG8ypY91Ujv3xM9uxk7xmxsaQNjQPcuFDbPiO0lNejToyuO1BoCbrh16ios3VEGIKwNZmTmVeCYfgcjrXd3zN9S0q4r40/9BV6/6TTHdnyRWYCHv9qAP1w4BA+PS9wISQRjLItzPtrsPEuuWb3ixRtOwduLd+LwPj2Q3q8nzhnSHycPPATf3n8uNu+pAgB069IJM/5wDuZvKTlAsIFwgTEqNFeN/AW2ldTgLl1tHo9uXTrhkcuGYuyww90/FNHO41cMw+F9ukf1cCKcNbgv7r9oCO44J/G3kUGXzuYt5uG/6GN6To+uJNZmnKBr0brl+etG4LxJi/DxXdYq+dHpfdt/Xzz0cEw4fzBKa5rw10tPdGXHFSMGYMueavz+PG/yrlItbYIgiFTFaks7pce0CYIgggaJNkEQRIAg0SYIgggQJNoEQRABgkSbIAgiQJBoEwRBBAgSbYIgiABBok0QBBEgpGyuYYyVAsh3eHl/AGUCzZFNkOwNkq0A2SsbslceTmw9hnOeZnaSFNF2A2Ms08quIFUIkr1BshUge2VD9spDpq00PEIQBBEgSLQJgiAChIqiPcVvA2wSJHuDZCtA9sqG7JWHNFuVG9MmCIIgjFGxpU0QBEEYQKJNEAQRIJQRbcbYOMbYNsZYDmNsoo92HMUYW8QY28IY28wY+7N2/CnGWBFjbJ323+W6ax7R7N7GGPsf3XFPnokxlscY26jZlakd68sYm88Y26H9/2HaccYYe0OzaQNjbJQundu183cwxm6XYOeJuve3jjFWzRh7UKV3yxibxhjbxxjbpDsm7F0yxk7XvlWOdq1xjDPn9r7EGMvWbJrBGDtUO57OGGvQvefJZnYZPbtge4V9f8bYYMbYKu3454yx6MCbYuz9XGdrHmNsnXbcm/fLOff9PwCdAewEcCyAbgDWAxjuky0DAIzSfvcGsB3AcABPAXgozvnDNXu7AxisPUdnL58JQB6A/jHHXgQwUfs9EcAk7fflAGYDYADGAFilHe8LYJf2/4dpvw+T/M33AjhGpXcL4AIAowBskvEuAfysncu0ay+TYO+lALpovyfp7E3XnxeTTly7jJ5dsL3Cvj+ALwDcpP2eDOA+0fbG/P0VAH/z8v2q0tI+E0AO53wX57wZwGcAxvthCOe8mHO+RvtdA2ArgIEJLhkP4DPOeRPnPBdADsLP4/czjQfwofb7QwDX6I5P52FWAjiUMTYAwP8AmM85r+Cc7wcwH8A4ifaNBbCTc55o56zn75ZzvgRARRw7XL9L7W99OOcrebiUTtelJcxezvk8znmr9s+VAAYlSsPELqNnF2ZvAmx9f631ejGAr7ywV7vfbwD8J1Eaot+vKqI9EECB7t+FSCyUnsAYSwdwGoBV2qEHtC7nNF03xsh2L5+JA5jHGMtijN2jHTuCc16s/d4LIBJNVwV7AeAmRGd2Vd8tIO5dDtR+xx6Xye8RbtlFGMwYW8sY+4kxdr52LJFdRs8uGhHfvx+ASl2FJfv9ng+ghHO+Q3dM+vtVRbSVgzHWC8DXAB7knFcDeBvAEACnAihGuFukCudxzkcBuAzA/YyxC/R/1Gp3ZdZ2auOMVwP4Ujuk8ruNQrV3mQjG2GMAWgF8oh0qBnA05/w0AP8L4FPGmHmYeQ2Jzx6Y7x/DbxHd8PDk/aoi2kUAjtL9e5B2zBcYY10RFuxPOOffAADnvIRz3sY5DwF4F+EuGmBsu2fPxDkv0v5/H4AZmm0lWrcs0j3bp4q9CFcuazjnJZrdyr5bDVHvsgjRQxXS7GaM3QHgSgA3a2IAbZihXPudhfC48Akmdhk9uzAEfv9yhIeousR5DqFo97gOwOe65/Dk/aoi2qsBHK/N/HZDuOv8nR+GaONUUwFs5Zy/qjs+QHfatQAis8nfAbiJMdadMTYYwPEITzp48kyMsYMZY70jvxGehNqk3SuyauF2ADN19t7GwowBUKV1z+YCuJQxdpjWPb1UOyaDqBaKqu9Wh5B3qf2tmjE2Rstnt+nSEgZjbByAhwFczTmv1x1PY4x11n4fi/D73GVil9Gzi7RXyPfXKqdFAG6Qaa/GJQCyOeftwx6evV87M6ky/0N4Jn47wrXTYz7acR7CXZQNANZp/10O4CMAG7Xj3wEYoLvmMc3ubdCtBvDimRCeQV+v/bc5ch+Ex/cWAtgBYAGAvtpxBuBNzaaNAEbr0vo9wpM9OQDulGTvwQi3iA7RHVPm3SJcmRQDaEF47PEuke8SwGiERWkngH9D25Us2N4chMd8I/l3snbu9VoeWQdgDYCrzOwyenbB9gr7/lp5+Fl7B18C6C7aXu34BwDujTnXk/dL29gJgiAChCrDIwRBEIQFSLQJgiACBIk2QRBEgCDRJgiCCBAk2gRBEAGCRJsgCCJAkGgTBEEEiP8Pyz2djQiaPgoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize original data\n",
    "plt.plot(actual_data_client, label=\"actual\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize original data\n",
    "plt.plot(imputed_data_client, label=\"imputed\")\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store the imputed data\n",
    "def store_imputed_data(n_users, L, dim, missing_percentage, imputed_data):\n",
    "    results_path = f\"../imputed_data/traffic\"\n",
    "    file_name = f\"numuser_{n_users}_L_{L}_dim_{dim}_missingPercentage_{missing_percentage}\"\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    np.save(file_path, imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store imputed data\n",
    "store_train = False\n",
    "if store_train:\n",
    "    store_imputed_data(n_users=20, L=100, dim=80, missing_percentage=0, imputed_data=imputed_data_flatten_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 168)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_test = False\n",
    "data_test_np = data_test.to_numpy().T\n",
    "data_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store the imputed data\n",
    "def store_test_data(test_data):\n",
    "    results_path = f\"../test_data/\"\n",
    "    file_name = f\"test_traff_data_168steps\"\n",
    "    file_path = os.path.join(results_path, file_name)\n",
    "    np.save(file_path, test_data)\n",
    "if store_test:\n",
    "    store_test_data(data_test_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
